{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e987df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 学習データの基本情報 ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      " 13  Transported   8693 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 891.5+ KB\n",
      "None\n",
      "\n",
      "=== テストデータの基本情報 ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4277 entries, 0 to 4276\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   4277 non-null   object \n",
      " 1   HomePlanet    4190 non-null   object \n",
      " 2   CryoSleep     4184 non-null   object \n",
      " 3   Cabin         4177 non-null   object \n",
      " 4   Destination   4185 non-null   object \n",
      " 5   Age           4186 non-null   float64\n",
      " 6   VIP           4184 non-null   object \n",
      " 7   RoomService   4195 non-null   float64\n",
      " 8   FoodCourt     4171 non-null   float64\n",
      " 9   ShoppingMall  4179 non-null   float64\n",
      " 10  Spa           4176 non-null   float64\n",
      " 11  VRDeck        4197 non-null   float64\n",
      " 12  Name          4183 non-null   object \n",
      "dtypes: float64(6), object(7)\n",
      "memory usage: 434.5+ KB\n",
      "None\n",
      "\n",
      "=== 全データの欠損値状況 ===\n",
      "PassengerId        0\n",
      "HomePlanet       288\n",
      "CryoSleep        310\n",
      "Cabin            299\n",
      "Destination      274\n",
      "Age              270\n",
      "VIP              296\n",
      "RoomService      263\n",
      "FoodCourt        289\n",
      "ShoppingMall     306\n",
      "Spa              284\n",
      "VRDeck           268\n",
      "Name             294\n",
      "Transported     4277\n",
      "dtype: int64\n",
      "\n",
      "=== 欠損値補完順序 (今回の対象: 最初の項目のみ) ===\n",
      "['HomePlanet']\n",
      "\n",
      "--- 補完対象カラム: HomePlanet ---\n",
      "HomePlanet のデータ型: object\n",
      "HomePlanet のユニーク値: ['Europa' 'Earth' 'Mars' nan]\n",
      "HomePlanet の欠損値数: 288\n",
      "\n",
      "--- HomePlanet の補完に使用する初期特徴量候補 ---\n",
      "['CryoSleep', 'VIP', 'Destination', 'Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
      "\n",
      "HomePlanet が非欠損のデータ数: 12682\n",
      "\n",
      "--- HomePlanet 補完モデル用データ準備完了 ---\n",
      "特徴量 (X) の形状: (12682, 12)\n",
      "目的変数 (y) の形状: (12682,)\n",
      "特徴量カラム: ['CryoSleep', 'VIP', 'Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Destination_55 Cancri e', 'Destination_PSO J318.5-22', 'Destination_TRAPPIST-1e', 'Destination_nan']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39046/681675186.py:69: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  features_df['CryoSleep'] = features_df['CryoSleep'].fillna(False).astype(int)\n",
      "/tmp/ipykernel_39046/681675186.py:70: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  features_df['VIP'] = features_df['VIP'].fillna(False).astype(int)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# データの読み込み (パスは適宜変更してください)\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# 学習データとテストデータの結合 (欠損値補完用)\n",
    "all_data = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "\n",
    "print(\"=== 学習データの基本情報 ===\")\n",
    "print(train_df.info())\n",
    "print(\"\\n=== テストデータの基本情報 ===\")\n",
    "print(test_df.info())\n",
    "print(\"\\n=== 全データの欠損値状況 ===\")\n",
    "print(all_data.isnull().sum())\n",
    "\n",
    "# 欠損値補完の順序を定義 (カテゴリ変数 -> 数値変数, 依存関係を考慮)\n",
    "# まずは 'HomePlanet' から始めましょう。これが比較的独立してそうなので。\n",
    "imputation_order = [\n",
    "    'HomePlanet', # 相対的に独立?\n",
    "    # 以下、順次追加していきます\n",
    "    # 'CryoSleep', # VIPや消費金額と関係ありそう?\n",
    "    # 'Destination', # HomePlanetやCryoSleepと関係あるかも?\n",
    "    # 'Age', # HomePlanet, CryoSleep, Cabinなどと関係ありそう\n",
    "    # 'VIP', # 特定のHomePlanetやCryoSleepと関係ありそう?\n",
    "    # 'Cabin', # HomePlanetやDestinationと関係ありそう (Deck/Side)\n",
    "    # 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck' # 相互に関連、CryoSleep, VIP, Cabinと関係\n",
    "    # 'Name' # 最後? または別途処理?\n",
    "]\n",
    "\n",
    "print(\"\\n=== 欠損値補完順序 (今回の対象: 最初の項目のみ) ===\")\n",
    "print(imputation_order)\n",
    "\n",
    "# 補完対象の最初のカラム\n",
    "target_col = imputation_order[0]\n",
    "print(f\"\\n--- 補完対象カラム: {target_col} ---\")\n",
    "\n",
    "# 補完対象カラムの情報を表示\n",
    "print(f\"{target_col} のデータ型: {all_data[target_col].dtype}\")\n",
    "print(f\"{target_col} のユニーク値: {all_data[target_col].unique()}\")\n",
    "print(f\"{target_col} の欠損値数: {all_data[target_col].isnull().sum()}\")\n",
    "\n",
    "# 欠損値補完に使用する特徴量の候補 (カテゴリ変数はOne-Hot, 数値変数はそのまま?)\n",
    "# PassengerId は GroupID と GroupSize に変換した方が良いかもしれないが、まずは基本的なもので。\n",
    "# Name は一旦除外。Cabin は Deck/Side に分解予定だが、まずはそのまま?\n",
    "initial_features = [\n",
    "    'CryoSleep', 'VIP', 'Destination',\n",
    "    # 数値変数 (Cabinは文字列なので除く、Nameも除く)\n",
    "    'Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'\n",
    "]\n",
    "\n",
    "print(f\"\\n--- {target_col} の補完に使用する初期特徴量候補 ---\")\n",
    "print(initial_features)\n",
    "\n",
    "# データ準備: 特徴量の選別と前処理 (One-Hot Encodingなど)\n",
    "# 1. 欠損値補完対象でない行を抽出 (ターゲットが存在する行)\n",
    "non_null_target_df = all_data[all_data[target_col].notnull()].copy()\n",
    "print(f\"\\n{target_col} が非欠損のデータ数: {len(non_null_target_df)}\")\n",
    "\n",
    "# 2. 使用する特徴量を抽出\n",
    "features_df = non_null_target_df[initial_features].copy()\n",
    "\n",
    "# 3. カテゴリ変数のOne-Hot Encoding (Destination)\n",
    "features_df = pd.get_dummies(features_df, columns=['Destination'], dummy_na=True) # dummy_na=True で欠損もカテゴリ化\n",
    "\n",
    "# 4. バイナリ変数の処理 (CryoSleep, VIP)\n",
    "# 欠損値はFalseとして扱うか、別途補完が必要か？ここでは簡単のため、欠損はFalseとして仮置き\n",
    "features_df['CryoSleep'] = features_df['CryoSleep'].fillna(False).astype(int)\n",
    "features_df['VIP'] = features_df['VIP'].fillna(False).astype(int)\n",
    "\n",
    "# 5. 数値変数の欠損値処理 (一時的に平均値で補完 - モデル学習用)\n",
    "# 実際の補完モデルの精度を上げるには、ここも別の方法が望ましいが、まずは進めます。\n",
    "numeric_cols_for_impute_model = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in numeric_cols_for_impute_model:\n",
    "     if col in features_df.columns: # 存在する場合のみ処理\n",
    "        features_df[col] = features_df[col].fillna(features_df[col].mean())\n",
    "\n",
    "# 6. 説明変数 (X) と目的変数 (y) の分離\n",
    "X = features_df\n",
    "y = non_null_target_df[target_col]\n",
    "\n",
    "print(f\"\\n--- {target_col} 補完モデル用データ準備完了 ---\")\n",
    "print(\"特徴量 (X) の形状:\", X.shape)\n",
    "print(\"目的変数 (y) の形状:\", y.shape)\n",
    "print(\"特徴量カラム:\", X.columns.tolist())\n",
    "\n",
    "# 次のセルでモデルの学習と予測を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "345fe1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GPU 利用確認 ===\n",
      "GPU 利用可否状況 (今回は全て False): {'LightGBM': False, 'XGBoost': False, 'CatBoost': False}\n",
      "\n",
      "=== モデル定義 (事前設定パラメータ & CPU) ===\n",
      "LightGBM: CPU 使用設定\n",
      "XGBoost: CPU 使用設定 (tree_method='hist')\n",
      "CatBoost: CPU 使用設定\n",
      "\n",
      "=== モデル評価 (交差検証) ===\n",
      "Evaluating LightGBM...\n",
      "  LightGBM - CV Accuracy: 0.74933 (+/- 0.01270), Time: 14.07s\n",
      "Evaluating CatBoost...\n",
      "  CatBoost - CV Accuracy: 0.74420 (+/- 0.00575), Time: -10.15s\n",
      "Evaluating XGBoost...\n",
      "  XGBoost - CV Accuracy: 0.74539 (+/- 0.01031), Time: 1.99s\n",
      "\n",
      "=== モデル比較結果 (CV Accuracy) ===\n",
      "LightGBM: 0.74933 (Time: 14.07s)\n",
      "XGBoost: 0.74539 (Time: 1.99s)\n",
      "CatBoost: 0.74420 (Time: -10.15s)\n",
      "\n",
      "--- 最も精度の高いモデル: LightGBM (CV Accuracy: 0.74933) ---\n"
     ]
    }
   ],
   "source": [
    "# --- データ準備 (前セルの続き) ---\n",
    "# X, y は前セルで定義済みです。\n",
    "# X.shape = (12682, 12)\n",
    "# y.shape = (12682,)  # dtype: object, unique: ['Europa' 'Earth' 'Mars']\n",
    "\n",
    "# --- 1. GPU 利用確認 (今回は省略し、すべて False とします) ---\n",
    "print(\"=== GPU 利用確認 ===\")\n",
    "gpu_available = {\n",
    "    'LightGBM': False,\n",
    "    'XGBoost': False,\n",
    "    'CatBoost': False\n",
    "}\n",
    "print(f\"GPU 利用可否状況 (今回は全て False): {gpu_available}\")\n",
    "\n",
    "# --- 2. モデル定義 (事前設定パラメータ & CPU) ---\n",
    "print(\"\\n=== モデル定義 (事前設定パラメータ & CPU) ===\")\n",
    "models = {}\n",
    "\n",
    "# LightGBM (CPU)\n",
    "import lightgbm as lgb\n",
    "lgb_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'metric': 'multi_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 200,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'min_child_samples': 20,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0.1,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'device': 'cpu'\n",
    "}\n",
    "print(\"LightGBM: CPU 使用設定\")\n",
    "models['LightGBM'] = lgb.LGBMClassifier(**lgb_params)\n",
    "\n",
    "# XGBoost (CPU)\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "xgb_params = {\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 3,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'booster': 'gbtree',\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 200,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "print(\"XGBoost: CPU 使用設定 (tree_method='hist')\")\n",
    "# XGBoost 用のモデルは、後で y を変換してから作成・評価します。\n",
    "\n",
    "# CatBoost (CPU)\n",
    "import catboost as cb\n",
    "cb_params = {\n",
    "    'loss_function': 'MultiClass',\n",
    "    'eval_metric': 'MultiClass',\n",
    "    'iterations': 200,\n",
    "    'depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'l2_leaf_reg': 3.0,\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "    'task_type': 'CPU'\n",
    "}\n",
    "print(\"CatBoost: CPU 使用設定\")\n",
    "models['CatBoost'] = cb.CatBoostClassifier(**cb_params)\n",
    "\n",
    "# --- 3. モデル評価 (交差検証) ---\n",
    "print(\"\\n=== モデル評価 (交差検証) ===\")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import time\n",
    "\n",
    "# 交差検証の設定\n",
    "cv_folds = 5\n",
    "# XGBoost 用に LabelEncoder を準備\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y) # Earth->0, Europa->1, Mars->2 などに変換\n",
    "# print(f\"元のラベル: {le.classes_}\") # 変換前後の対応を確認できます\n",
    "# print(f\"変換後のラベル: {np.unique(y_encoded)}\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "scoring_metric = 'accuracy'\n",
    "\n",
    "model_scores = {}\n",
    "model_times = {}\n",
    "\n",
    "# LightGBM と CatBoost の評価 (元のラベル y を使用)\n",
    "for name in ['LightGBM', 'CatBoost']:\n",
    "    model = models[name]\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        scores = cross_val_score(model, X, y, cv=skf, scoring=scoring_metric, n_jobs=1)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error during CV for {name}: {e}\")\n",
    "        model_scores[name] = np.nan\n",
    "        model_times[name] = time.time() - start_time\n",
    "        continue\n",
    "\n",
    "    end_time = time.time()\n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    model_scores[name] = mean_score\n",
    "    model_times[name] = elapsed_time\n",
    "    print(f\"  {name} - CV Accuracy: {mean_score:.5f} (+/- {std_score * 2:.5f}), Time: {elapsed_time:.2f}s\")\n",
    "\n",
    "# XGBoost の評価 (数値ラベル y_encoded を使用)\n",
    "print(f\"Evaluating XGBoost...\")\n",
    "model_xgb = xgb.XGBClassifier(**xgb_params, enable_categorical=False)\n",
    "start_time = time.time()\n",
    "try:\n",
    "    # XGBoost にはエンコードされた y を渡す\n",
    "    scores = cross_val_score(model_xgb, X, y_encoded, cv=skf, scoring=scoring_metric, n_jobs=1)\n",
    "except Exception as e:\n",
    "    print(f\"  Error during CV for XGBoost: {e}\")\n",
    "    model_scores['XGBoost'] = np.nan\n",
    "    model_times['XGBoost'] = time.time() - start_time\n",
    "else:\n",
    "    end_time = time.time()\n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    model_scores['XGBoost'] = mean_score\n",
    "    model_times['XGBoost'] = elapsed_time\n",
    "    print(f\"  XGBoost - CV Accuracy: {mean_score:.5f} (+/- {std_score * 2:.5f}), Time: {elapsed_time:.2f}s\")\n",
    "\n",
    "# --- 4. 結果出力 ---\n",
    "print(\"\\n=== モデル比較結果 (CV Accuracy) ===\")\n",
    "sorted_models = sorted(\n",
    "    [(name, score) for name, score in model_scores.items() if not np.isnan(score)],\n",
    "    key=lambda item: item[1], reverse=True\n",
    ")\n",
    "for name, score in sorted_models:\n",
    "    print(f\"{name}: {score:.5f} (Time: {model_times[name]:.2f}s)\")\n",
    "\n",
    "if sorted_models:\n",
    "    best_model_name, best_model_score = sorted_models[0]\n",
    "    print(f\"\\n--- 最も精度の高いモデル: {best_model_name} (CV Accuracy: {best_model_score:.5f}) ---\")\n",
    "else:\n",
    "    print(\"\\n--- モデル評価結果がありません ---\")\n",
    "    best_model_name = None\n",
    "\n",
    "# 次のセルで、選ばれた最良モデルで実際に欠損値を補完します。\n",
    "# best_model_name に応じて、適切な y (または y_encoded) とモデルを使用して学習・予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55311cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HomePlanet 欠損値補完の準備 ===\n",
      "HomePlanet が欠損しているデータ数: 288\n",
      "\n",
      "=== HomePlanet 補完モデル (LightGBM) の学習 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39046/3076633070.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  features_for_prediction_df['CryoSleep'] = features_for_prediction_df['CryoSleep'].fillna(False).astype(int)\n",
      "/tmp/ipykernel_39046/3076633070.py:38: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  features_for_prediction_df['VIP'] = features_for_prediction_df['VIP'].fillna(False).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習完了\n",
      "\n",
      "=== HomePlanet 欠損値の予測 ===\n",
      "予測された HomePlanet ラベル: ['Earth' 'Europa' 'Europa' 'Mars' 'Europa' 'Earth' 'Earth' 'Mars' 'Earth'\n",
      " 'Europa' 'Mars' 'Earth' 'Earth' 'Europa' 'Mars' 'Europa' 'Earth' 'Mars'\n",
      " 'Earth' 'Mars' 'Europa' 'Europa' 'Mars' 'Earth' 'Earth' 'Earth' 'Europa'\n",
      " 'Earth' 'Europa' 'Earth' 'Earth' 'Earth' 'Earth' 'Europa' 'Earth' 'Earth'\n",
      " 'Earth' 'Earth' 'Earth' 'Earth' 'Earth' 'Earth' 'Earth' 'Earth' 'Earth'\n",
      " 'Earth' 'Earth' 'Earth' 'Mars' 'Earth' 'Mars' 'Earth' 'Europa' 'Mars'\n",
      " 'Earth' 'Earth' 'Earth' 'Europa' 'Earth' 'Earth' 'Mars' 'Earth' 'Earth'\n",
      " 'Earth' 'Earth' 'Earth' 'Earth' 'Earth' 'Earth' 'Earth' 'Earth' 'Earth'\n",
      " 'Earth' 'Europa' 'Earth' 'Earth' 'Earth' 'Europa' 'Earth' 'Europa'\n",
      " 'Earth' 'Earth' 'Earth' 'Europa' 'Earth' 'Earth' 'Earth' 'Europa' 'Earth'\n",
      " 'Europa' 'Mars' 'Earth' 'Earth' 'Earth' 'Earth' 'Earth' 'Mars' 'Earth'\n",
      " 'Europa' 'Europa' 'Earth' 'Europa' 'Earth' 'Earth' 'Earth' 'Mars' 'Mars'\n",
      " 'Earth' 'Earth' 'Earth' 'Earth' 'Europa' 'Earth' 'Earth' 'Earth' 'Earth'\n",
      " 'Earth' 'Earth' 'Earth' 'Europa' 'Mars' 'Europa' 'Earth' 'Europa' 'Mars'\n",
      " 'Earth' 'Earth' 'Earth' 'Earth' 'Europa' 'Earth' 'Earth' 'Mars' 'Europa'\n",
      " 'Europa' 'Earth' 'Earth' 'Earth' 'Mars' 'Earth' 'Earth' 'Europa' 'Mars'\n",
      " 'Earth' 'Europa' 'Europa' 'Earth' 'Earth' 'Mars' 'Mars' 'Earth' 'Earth'\n",
      " 'Earth' 'Earth' 'Earth' 'Europa' 'Earth' 'Earth' 'Europa' 'Earth' 'Earth'\n",
      " 'Mars' 'Europa' 'Earth' 'Earth' 'Earth' 'Europa' 'Earth' 'Europa' 'Earth'\n",
      " 'Earth' 'Mars' 'Mars' 'Earth' 'Earth' 'Mars' 'Europa' 'Earth' 'Mars'\n",
      " 'Earth' 'Earth' 'Europa' 'Europa' 'Earth' 'Earth' 'Europa' 'Europa'\n",
      " 'Mars' 'Earth' 'Earth' 'Earth' 'Earth' 'Earth' 'Earth' 'Europa' 'Earth'\n",
      " 'Mars' 'Europa' 'Earth' 'Mars' 'Earth' 'Europa' 'Mars' 'Earth' 'Earth'\n",
      " 'Earth' 'Earth' 'Earth' 'Earth' 'Earth' 'Europa' 'Europa' 'Mars' 'Earth'\n",
      " 'Earth' 'Earth' 'Earth' 'Earth' 'Europa' 'Europa' 'Earth' 'Europa'\n",
      " 'Earth' 'Europa' 'Earth' 'Europa' 'Europa' 'Earth' 'Earth' 'Europa'\n",
      " 'Earth' 'Mars' 'Europa' 'Earth' 'Mars' 'Europa' 'Europa' 'Earth' 'Earth'\n",
      " 'Mars' 'Mars' 'Europa' 'Earth' 'Mars' 'Earth' 'Earth' 'Mars' 'Mars'\n",
      " 'Earth' 'Earth' 'Earth' 'Earth' 'Europa' 'Mars' 'Earth' 'Mars' 'Earth'\n",
      " 'Mars' 'Mars' 'Mars' 'Mars' 'Mars' 'Europa' 'Earth' 'Europa' 'Europa'\n",
      " 'Mars' 'Earth' 'Earth' 'Earth' 'Earth' 'Mars' 'Europa' 'Earth' 'Europa'\n",
      " 'Earth' 'Earth' 'Earth' 'Mars' 'Earth' 'Earth' 'Earth' 'Europa' 'Earth'\n",
      " 'Earth' 'Europa' 'Earth' 'Mars']\n",
      "\n",
      "=== 補完結果の反映 ===\n",
      "HomePlanet 列の欠損値が補完されました。\n",
      "\n",
      "補完後の全データを '../data/all_data_imputed_step1_HomePlanet.csv' に保存しました。\n",
      "\n",
      "=== 次の補完対象カラム 'CryoSleep' の欠損状況 ===\n",
      "'CryoSleep' の欠損値数: 310\n"
     ]
    }
   ],
   "source": [
    "# --- 前提条件 ---\n",
    "# best_model_name = 'LightGBM' (前セルの結果)\n",
    "# all_data: 元の全データ (train + test 結合)\n",
    "# X: モデル学習に使った特徴量 (HomePlanet 予測用)\n",
    "# y: モデル学習に使った目的変数 (HomePlanet, 文字列ラベル)\n",
    "# initial_features: X を作成したのに使ったカラム名リスト\n",
    "\n",
    "print(\"=== HomePlanet 欠損値補完の準備 ===\")\n",
    "# 1. 補完対象データの特定 (HomePlanet が欠損している行)\n",
    "missing_homeplanet_mask = all_data['HomePlanet'].isnull()\n",
    "missing_homeplanet_indices = all_data[missing_homeplanet_mask].index\n",
    "print(f\"HomePlanet が欠損しているデータ数: {len(missing_homeplanet_indices)}\")\n",
    "\n",
    "# 2. 補完に使用する特徴量の準備 (欠損行のみ)\n",
    "#    X (学習データ) と同じ前処理を適用する必要があります。\n",
    "features_for_prediction_df = all_data.loc[missing_homeplanet_indices, initial_features].copy()\n",
    "\n",
    "# 3. 特徴量の前処理 (学習時と同様)\n",
    "#    - Destination の One-Hot Encoding\n",
    "features_for_prediction_df = pd.get_dummies(features_for_prediction_df, columns=['Destination'], dummy_na=True)\n",
    "\n",
    "#    - 学習データの One-Hot 後のカラムに合わせる (存在しないカテゴリは0で埋める)\n",
    "#      例: 学習データに 'Destination_nan' が無く、予測データにあった場合、削除する。\n",
    "#      例: 学習データに 'Destination_PSO J318.5-22' があり、予測データに無かった場合、0で追加する。\n",
    "#      `X` のカラムが基準\n",
    "for col in X.columns: # X は学習に使った特徴量\n",
    "    if col not in features_for_prediction_df.columns:\n",
    "        features_for_prediction_df[col] = 0 # 学習時にあったが予測時にない列は0で追加\n",
    "for col in features_for_prediction_df.columns:\n",
    "    if col not in X.columns:\n",
    "        features_for_prediction_df.drop(columns=[col], inplace=True) # 予測時にあったが学習時にない列は削除\n",
    "\n",
    "#    - カラムの並び順を学習時と一致させる\n",
    "features_for_prediction_df = features_for_prediction_df[X.columns] # X.columns は学習時のカラム順序\n",
    "\n",
    "#    - CryoSleep, VIP の処理 (学習時と同様に欠損は False と仮定)\n",
    "features_for_prediction_df['CryoSleep'] = features_for_prediction_df['CryoSleep'].fillna(False).astype(int)\n",
    "features_for_prediction_df['VIP'] = features_for_prediction_df['VIP'].fillna(False).astype(int)\n",
    "\n",
    "#    - 数値変数の欠損値処理 (学習時の平均値で補完 - モデル入力用)\n",
    "#      重要: 学習データ X の平均値を使う！\n",
    "numeric_cols_for_impute_model = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in numeric_cols_for_impute_model:\n",
    "    if col in features_for_prediction_df.columns:\n",
    "        # 学習データ X の平均値を取得\n",
    "        train_mean = X[col].mean()\n",
    "        features_for_prediction_df[col] = features_for_prediction_df[col].fillna(train_mean)\n",
    "\n",
    "# 4. モデルの学習 (評価済みの best_model_name が 'LightGBM' であることを前提)\n",
    "print(f\"\\n=== HomePlanet 補完モデル ({best_model_name}) の学習 ===\")\n",
    "# 評価時に使用した X, y を使って最終モデルを学習\n",
    "final_imputer_model = models[best_model_name] # models は前セルで定義済み\n",
    "final_imputer_model.fit(X, y) # LightGBM は文字列ラベル y をそのまま使える\n",
    "print(\"学習完了\")\n",
    "\n",
    "# 5. 欠損値の予測\n",
    "print(\"\\n=== HomePlanet 欠損値の予測 ===\")\n",
    "predicted_homeplanets = final_imputer_model.predict(features_for_prediction_df)\n",
    "print(f\"予測された HomePlanet ラベル: {predicted_homeplanets}\")\n",
    "\n",
    "# 6. 元のデータフレームに補完結果を反映\n",
    "print(\"\\n=== 補完結果の反映 ===\")\n",
    "all_data.loc[missing_homeplanet_indices, 'HomePlanet'] = predicted_homeplanets\n",
    "print(\"HomePlanet 列の欠損値が補完されました。\")\n",
    "\n",
    "# 7. 新しいCSVファイルへの保存 (修正箇所: ディレクトリの存在確認と作成)\n",
    "import os # os モジュールのインポートを追加\n",
    "\n",
    "output_file_path = '../data/all_data_imputed_step1_HomePlanet.csv'\n",
    "\n",
    "# ディレクトリ 'data' が存在しない場合は作成\n",
    "directory = os.path.dirname(output_file_path)\n",
    "if directory and not os.path.exists(directory): # directory が空文字でないことを確認\n",
    "    os.makedirs(directory)\n",
    "    print(f\"ディレクトリ '{directory}' を作成しました。\")\n",
    "\n",
    "all_data.to_csv(output_file_path, index=False)\n",
    "print(f\"\\n補完後の全データを '{output_file_path}' に保存しました。\")\n",
    "\n",
    "# 8. 次のステップへの準備\n",
    "# 次は CryoSleep です。その前に、データの状態を確認します。\n",
    "print(f\"\\n=== 次の補完対象カラム 'CryoSleep' の欠損状況 ===\")\n",
    "print(f\"'CryoSleep' の欠損値数: {all_data['CryoSleep'].isnull().sum()}\")\n",
    "\n",
    "# 次のステップでは、'CryoSleep' の補完モデルを作成・評価します。\n",
    "# 必要に応じて、'HomePlanet' の補完結果も特徴量として使用できます。\n",
    "# 次のセルで進めていきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40e7f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CryoSleep 欠損値補完の準備 ===\n",
      "CryoSleep が欠損しているデータ数: 310\n",
      "\n",
      "--- CryoSleep の補完に使用する特徴量候補 ---\n",
      "['HomePlanet', 'Destination', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
      "\n",
      "CryoSleep が非欠損のデータ数: 12660\n",
      "\n",
      "--- y_cryosleep のデータ型確認 ---\n",
      "y_cryosleep の dtype: object\n",
      "y_cryosleep のユニーク値: [False True]\n",
      "y_cryosleep を object から bool に変換しました。\n",
      "変換後の dtype: bool\n",
      "変換後のユニーク値: [False  True]\n",
      "\n",
      "--- 特徴量の前処理 ---\n",
      "特徴量前処理完了\n",
      "\n",
      "=== CryoSleep 補完モデルの定義 (CPU) ===\n",
      "LightGBM: CPU 使用設定\n",
      "XGBoost: CPU 使用設定 (tree_method='hist')\n",
      "CatBoost: CPU 使用設定\n",
      "RandomForest: 設定\n",
      "\n",
      "=== CryoSleep モデル評価 (交差検証) ===\n",
      "Evaluating LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39046/2446711619.py:62: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_cryosleep_processed['VIP'] = X_cryosleep_processed['VIP'].fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM - CV Accuracy: 0.95340 (+/- 0.00522), Time: 12.66s\n",
      "Evaluating XGBoost...\n",
      "  XGBoost - CV Accuracy: 0.95427 (+/- 0.00437), Time: -11.79s\n",
      "Evaluating CatBoost...\n",
      "  CatBoost - CV Accuracy: 0.95016 (+/- 0.00627), Time: 0.96s\n",
      "Evaluating RandomForest...\n",
      "  RandomForest - CV Accuracy: 0.93160 (+/- 0.00726), Time: 0.94s\n",
      "\n",
      "=== CryoSleep モデル比較結果 (CV Accuracy) ===\n",
      "XGBoost: 0.95427 (Time: -11.79s)\n",
      "LightGBM: 0.95340 (Time: 12.66s)\n",
      "CatBoost: 0.95016 (Time: 0.96s)\n",
      "RandomForest: 0.93160 (Time: 0.94s)\n",
      "\n",
      "--- CryoSleep 補完に最も適したモデル: XGBoost (CV Accuracy: 0.95427) ---\n"
     ]
    }
   ],
   "source": [
    "# --- 前提条件 ---\n",
    "# all_data は HomePlanet が補完された状態\n",
    "\n",
    "print(\"=== CryoSleep 欠損値補完の準備 ===\")\n",
    "\n",
    "# 1. 補完対象データの特定 (CryoSleep が欠損している行)\n",
    "missing_cryosleep_mask = all_data['CryoSleep'].isnull()\n",
    "missing_cryosleep_indices = all_data[missing_cryosleep_mask].index\n",
    "print(f\"CryoSleep が欠損しているデータ数: {len(missing_cryosleep_indices)}\")\n",
    "\n",
    "# 2. 特徴量の選定\n",
    "cryosleep_features = [\n",
    "    'HomePlanet', 'Destination', 'Age', 'VIP',\n",
    "    'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'\n",
    "]\n",
    "\n",
    "print(f\"\\n--- CryoSleep の補完に使用する特徴量候補 ---\")\n",
    "print(cryosleep_features)\n",
    "\n",
    "# 3. モデル学習用データの準備 (CryoSleep がわかっているデータ)\n",
    "non_null_cryosleep_df = all_data[all_data['CryoSleep'].notnull()].copy()\n",
    "print(f\"\\nCryoSleep が非欠損のデータ数: {len(non_null_cryosleep_df)}\")\n",
    "\n",
    "#    特徴量と目的変数の分離\n",
    "X_cryosleep = non_null_cryosleep_df[cryosleep_features].copy()\n",
    "y_cryosleep = non_null_cryosleep_df['CryoSleep'].copy() # bool型のはず\n",
    "\n",
    "# --- 重要な追加: y_cryosleep のデータ型を確認・修正 ---\n",
    "print(f\"\\n--- y_cryosleep のデータ型確認 ---\")\n",
    "print(f\"y_cryosleep の dtype: {y_cryosleep.dtype}\")\n",
    "print(f\"y_cryosleep のユニーク値: {y_cryosleep.unique()}\")\n",
    "\n",
    "# データ型が bool でない場合、明示的に変換\n",
    "# pd.BooleanDtype() を使うと、NaN も扱える nullable boolean になるが、\n",
    "# scikit-learn モデルには bool が普通使われる。\n",
    "# ここでは、non-null なデータだけを取り出しているので、標準の bool でOK。\n",
    "# ただし、念のため object 型なら変換を試みる。\n",
    "if y_cryosleep.dtype == 'object':\n",
    "    # object 型の場合、True/False/'True'/'False' などを bool に変換\n",
    "    y_cryosleep = y_cryosleep.map({'True': True, 'False': False, True: True, False: False})\n",
    "    print(f\"y_cryosleep を object から bool に変換しました。\")\n",
    "    print(f\"変換後の dtype: {y_cryosleep.dtype}\")\n",
    "    print(f\"変換後のユニーク値: {y_cryosleep.unique()}\")\n",
    "elif y_cryosleep.dtype != 'bool':\n",
    "    # その他の型の場合も、念のため変換を試みる\n",
    "    try:\n",
    "        y_cryosleep = y_cryosleep.astype(bool)\n",
    "        print(f\"y_cryosleep を {y_cryosleep.dtype} から bool に変換しました。\")\n",
    "    except (ValueError, TypeError) as e:\n",
    "        print(f\"y_cryosleep の型変換中にエラーが発生しました: {e}\")\n",
    "        print(\"モデル評価を続行できません。\")\n",
    "        raise # エラーを再送出して処理を停止\n",
    "\n",
    "# 4. 特徴量の前処理\n",
    "print(f\"\\n--- 特徴量の前処理 ---\")\n",
    "#    - カテゴリ変数の処理 (HomePlanet, Destination)\n",
    "X_cryosleep_processed = pd.get_dummies(X_cryosleep, columns=['HomePlanet', 'Destination'], dummy_na=True)\n",
    "\n",
    "#    - バイナリ変数の処理 (VIP)\n",
    "#      欠損値は False として扱います。\n",
    "#      警告を避けるために、infer_objects を使うか、astype 前に明示的に処理\n",
    "X_cryosleep_processed['VIP'] = X_cryosleep_processed['VIP'].fillna(False)\n",
    "# pd.set_option('future.no_silent_downcasting', True) # 必要に応じて有効化\n",
    "X_cryosleep_processed['VIP'] = X_cryosleep_processed['VIP'].astype(int) # True/False -> 1/0\n",
    "\n",
    "#    - 数値変数の欠損値処理\n",
    "numeric_cols_for_cryosleep = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in numeric_cols_for_cryosleep:\n",
    "    if col in X_cryosleep_processed.columns:\n",
    "        X_cryosleep_processed[col] = X_cryosleep_processed[col].fillna(X_cryosleep_processed[col].mean())\n",
    "\n",
    "print(\"特徴量前処理完了\")\n",
    "\n",
    "# 5. モデルの定義と比較 (CPU モード)\n",
    "print(\"\\n=== CryoSleep 補完モデルの定義 (CPU) ===\")\n",
    "# (モデル定義部分は変更なし)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "models_cryosleep = {}\n",
    "\n",
    "# LightGBM (CPU)\n",
    "lgb_params_cs = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 100,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'device': 'cpu'\n",
    "}\n",
    "print(\"LightGBM: CPU 使用設定\")\n",
    "models_cryosleep['LightGBM'] = lgb.LGBMClassifier(**lgb_params_cs)\n",
    "\n",
    "# XGBoost (CPU)\n",
    "xgb_params_cs = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'booster': 'gbtree',\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 100,\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "print(\"XGBoost: CPU 使用設定 (tree_method='hist')\")\n",
    "models_cryosleep['XGBoost'] = xgb.XGBClassifier(**xgb_params_cs, enable_categorical=False)\n",
    "\n",
    "# CatBoost (CPU)\n",
    "cb_params_cs = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'Logloss',\n",
    "    'iterations': 100,\n",
    "    'depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "    'task_type': 'CPU'\n",
    "}\n",
    "print(\"CatBoost: CPU 使用設定\")\n",
    "models_cryosleep['CatBoost'] = cb.CatBoostClassifier(**cb_params_cs)\n",
    "\n",
    "# RandomForest\n",
    "rf_params_cs = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "print(\"RandomForest: 設定\")\n",
    "models_cryosleep['RandomForest'] = RandomForestClassifier(**rf_params_cs)\n",
    "\n",
    "# --- 6. モデル評価 (交差検証) ---\n",
    "print(\"\\n=== CryoSleep モデル評価 (交差検証) ===\")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import time\n",
    "\n",
    "# 交差検証の設定\n",
    "cv_folds = 5\n",
    "skf_cs = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "scoring_metric_cs = 'accuracy'\n",
    "\n",
    "model_scores_cs = {}\n",
    "model_times_cs = {}\n",
    "\n",
    "for name, model in models_cryosleep.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        # n_jobs=1 にして、並列処理によるトラブルを避ける\n",
    "        scores = cross_val_score(model, X_cryosleep_processed, y_cryosleep, cv=skf_cs, scoring=scoring_metric_cs, n_jobs=1)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error during CV for {name}: {e}\")\n",
    "        model_scores_cs[name] = np.nan\n",
    "        model_times_cs[name] = time.time() - start_time\n",
    "        continue\n",
    "\n",
    "    end_time = time.time()\n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    model_scores_cs[name] = mean_score\n",
    "    model_times_cs[name] = elapsed_time\n",
    "\n",
    "    print(f\"  {name} - CV Accuracy: {mean_score:.5f} (+/- {std_score * 2:.5f}), Time: {elapsed_time:.2f}s\")\n",
    "\n",
    "# --- 7. 結果出力 ---\n",
    "print(\"\\n=== CryoSleep モデル比較結果 (CV Accuracy) ===\")\n",
    "sorted_models_cs = sorted(\n",
    "    [(name, score) for name, score in model_scores_cs.items() if not np.isnan(score)],\n",
    "    key=lambda item: item[1], reverse=True\n",
    ")\n",
    "for name, score in sorted_models_cs:\n",
    "    print(f\"{name}: {score:.5f} (Time: {model_times_cs[name]:.2f}s)\")\n",
    "\n",
    "if sorted_models_cs:\n",
    "    best_model_name_cs, best_model_score_cs = sorted_models_cs[0]\n",
    "    print(f\"\\n--- CryoSleep 補完に最も適したモデル: {best_model_name_cs} (CV Accuracy: {best_model_score_cs:.5f}) ---\")\n",
    "else:\n",
    "    print(\"\\n--- CryoSleep モデル評価結果がありません ---\")\n",
    "    best_model_name_cs = None\n",
    "\n",
    "# 次のセルで、選ばれた最良モデルで実際に CryoSleep の欠損値を補完します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a08ef0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CryoSleep 欠損値補完の実行 ===\n",
      "CryoSleep が欠損しているデータ数: 310\n",
      "\n",
      "=== CryoSleep 補完モデル (XGBoost) の学習 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39046/1675162488.py:35: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  features_for_prediction_cs_df['VIP'] = features_for_prediction_cs_df['VIP'].fillna(False).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習完了\n",
      "\n",
      "=== CryoSleep 欠損値の予測 ===\n",
      "予測された CryoSleep ラベル (最初の10件): [1 0 0 1 0 1 0 1 0 1]\n",
      "予測結果のデータ型: int64\n",
      "\n",
      "=== 補完結果の反映 ===\n",
      "CryoSleep 列の欠損値が補完されました。\n",
      "\n",
      "補完後の全データを '../data/all_data_imputed_step2_CryoSleep.csv' に保存しました。\n",
      "\n",
      "=== 次の補完対象カラム 'Destination' の欠損状況 ===\n",
      "'Destination' の欠損値数: 274\n"
     ]
    }
   ],
   "source": [
    "# --- 前提条件 ---\n",
    "# best_model_name_cs = 'XGBoost' (前セルの結果)\n",
    "# all_data は HomePlanet が補完された状態 (メモリ上または ../data/all_data_imputed_step1_HomePlanet.csv から読み込み済み)\n",
    "# X_cryosleep_processed, y_cryosleep は前セルで定義済み (モデル学習用の特徴量と目的変数)\n",
    "# cryosleep_features は前セルで定義済み (使用する特徴量のリスト)\n",
    "# models_cryosleep は前セルで定義済み (モデル辞書)\n",
    "\n",
    "print(\"=== CryoSleep 欠損値補完の実行 ===\")\n",
    "\n",
    "# 1. 補完対象データの特定 (CryoSleep が欠損している行)\n",
    "missing_cryosleep_mask = all_data['CryoSleep'].isnull()\n",
    "missing_cryosleep_indices = all_data[missing_cryosleep_mask].index\n",
    "print(f\"CryoSleep が欠損しているデータ数: {len(missing_cryosleep_indices)}\")\n",
    "\n",
    "# 2. 補完に使用する特徴量の準備 (欠損行のみ)\n",
    "features_for_prediction_cs_df = all_data.loc[missing_cryosleep_indices, cryosleep_features].copy()\n",
    "\n",
    "# 3. 特徴量の前処理 (学習時と同様)\n",
    "#    - カテゴリ変数の処理 (HomePlanet, Destination)\n",
    "features_for_prediction_cs_df = pd.get_dummies(features_for_prediction_cs_df, columns=['HomePlanet', 'Destination'], dummy_na=True)\n",
    "\n",
    "#    - 学習データの One-Hot 後のカラムに合わせる\n",
    "#      `X_cryosleep_processed` のカラムが基準\n",
    "for col in X_cryosleep_processed.columns: # 学習時のカラム\n",
    "    if col not in features_for_prediction_cs_df.columns:\n",
    "        features_for_prediction_cs_df[col] = 0 # 学習時にあったが予測時にない列は0で追加\n",
    "for col in features_for_prediction_cs_df.columns:\n",
    "    if col not in X_cryosleep_processed.columns:\n",
    "        features_for_prediction_cs_df.drop(columns=[col], inplace=True) # 予測時にあったが学習時にない列は削除\n",
    "\n",
    "#    - カラムの並び順を学習時と一致させる\n",
    "features_for_prediction_cs_df = features_for_prediction_cs_df[X_cryosleep_processed.columns]\n",
    "\n",
    "#    - バイナリ変数の処理 (VIP)\n",
    "features_for_prediction_cs_df['VIP'] = features_for_prediction_cs_df['VIP'].fillna(False).astype(int)\n",
    "\n",
    "#    - 数値変数の欠損値処理 (学習データの平均値で補完 - モデル入力用)\n",
    "#      重要: 学習データ X_cryosleep_processed の平均値を使う！\n",
    "numeric_cols_for_cryosleep = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in numeric_cols_for_cryosleep:\n",
    "    if col in features_for_prediction_cs_df.columns:\n",
    "        # 学習データの平均値を取得\n",
    "        train_mean = X_cryosleep_processed[col].mean()\n",
    "        features_for_prediction_cs_df[col] = features_for_prediction_cs_df[col].fillna(train_mean)\n",
    "\n",
    "# 4. モデルの学習 (評価済みの best_model_name_cs が 'XGBoost' であることを前提)\n",
    "print(f\"\\n=== CryoSleep 補完モデル ({best_model_name_cs}) の学習 ===\")\n",
    "# 評価時に使用した X_cryosleep_processed, y_cryosleep を使って最終モデルを学習\n",
    "final_imputer_model_cs = models_cryosleep[best_model_name_cs] # models_cryosleep は前セルで定義済み\n",
    "final_imputer_model_cs.fit(X_cryosleep_processed, y_cryosleep) # XGBoost は bool ラベル y_cryosleep をそのまま使える\n",
    "print(\"学習完了\")\n",
    "\n",
    "# 5. 欠損値の予測\n",
    "print(\"\\n=== CryoSleep 欠損値の予測 ===\")\n",
    "predicted_cryosleeps = final_imputer_model_cs.predict(features_for_prediction_cs_df)\n",
    "# 予測結果は bool 型 (True/False) であることを確認\n",
    "print(f\"予測された CryoSleep ラベル (最初の10件): {predicted_cryosleeps[:10]}\")\n",
    "print(f\"予測結果のデータ型: {predicted_cryosleeps.dtype}\")\n",
    "\n",
    "# 6. 元のデータフレームに補完結果を反映\n",
    "print(\"\\n=== 補完結果の反映 ===\")\n",
    "# bool 型の予測結果を直接代入\n",
    "all_data.loc[missing_cryosleep_indices, 'CryoSleep'] = predicted_cryosleeps\n",
    "print(\"CryoSleep 列の欠損値が補完されました。\")\n",
    "\n",
    "# 7. 新しいCSVファイルへの保存\n",
    "# ファイルパスの確認と作成 (必要に応じて)\n",
    "import os\n",
    "data_dir = \"../data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    print(f\"ディレクトリ '{data_dir}' を作成しました。\")\n",
    "\n",
    "output_file_path_cs = os.path.join(data_dir, 'all_data_imputed_step2_CryoSleep.csv')\n",
    "all_data.to_csv(output_file_path_cs, index=False)\n",
    "print(f\"\\n補完後の全データを '{output_file_path_cs}' に保存しました。\")\n",
    "\n",
    "# 8. 次のステップへの準備\n",
    "# 次は Destination です。その前に、データの状態を確認します。\n",
    "print(f\"\\n=== 次の補完対象カラム 'Destination' の欠損状況 ===\")\n",
    "print(f\"'Destination' の欠損値数: {all_data['Destination'].isnull().sum()}\")\n",
    "\n",
    "# 次のステップでは、'Destination' の補完モデルを作成・評価します。\n",
    "# CryoSleep の補完結果も特徴量として使用できます。\n",
    "# 次のセル (セル 6) で進めていきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "077facd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Destination 欠損値補完の準備 ===\n",
      "Destination が欠損しているデータ数: 274\n",
      "\n",
      "--- Destination の補完に使用する特徴量候補 ---\n",
      "['HomePlanet', 'CryoSleep', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
      "\n",
      "Destination が非欠損のデータ数: 12696\n",
      "\n",
      "--- 特徴量の前処理 ---\n",
      "\n",
      "=== Destination 補完モデルの定義 (CPU) ===\n",
      "LightGBM: CPU 使用設定\n",
      "XGBoost: CPU 使用設定 (tree_method='hist') - LabelEncoder を使用\n",
      "CatBoost: CPU 使用設定\n",
      "RandomForest: 設定\n",
      "\n",
      "=== Destination モデル評価 (交差検証) ===\n",
      "Evaluating LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39046/1441826967.py:35: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_destination_processed['VIP'] = X_destination_processed['VIP'].fillna(False).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM - CV Accuracy: 0.69274 (+/- 0.01196), Time: 0.88s\n",
      "Evaluating CatBoost...\n",
      "  CatBoost - CV Accuracy: 0.69841 (+/- 0.00400), Time: 1.69s\n",
      "Evaluating RandomForest...\n",
      "  RandomForest - CV Accuracy: 0.69542 (+/- 0.00997), Time: 0.95s\n",
      "Evaluating XGBoost...\n",
      "  XGBoost - CV Accuracy: 0.69455 (+/- 0.01144), Time: 2.34s\n",
      "\n",
      "=== Destination モデル比較結果 (CV Accuracy) ===\n",
      "CatBoost: 0.69841 (Time: 1.69s)\n",
      "RandomForest: 0.69542 (Time: 0.95s)\n",
      "XGBoost: 0.69455 (Time: 2.34s)\n",
      "LightGBM: 0.69274 (Time: 0.88s)\n",
      "\n",
      "--- Destination 補完に最も適したモデル: CatBoost (CV Accuracy: 0.69841) ---\n"
     ]
    }
   ],
   "source": [
    "# --- 前提条件 ---\n",
    "# all_data は HomePlanet と CryoSleep が補完された状態\n",
    "# ここでは all_data が既に更新されている前提\n",
    "\n",
    "print(\"=== Destination 欠損値補完の準備 ===\")\n",
    "\n",
    "# 1. 補完対象データの特定 (Destination が欠損している行)\n",
    "missing_destination_mask = all_data['Destination'].isnull()\n",
    "missing_destination_indices = all_data[missing_destination_mask].index\n",
    "print(f\"Destination が欠損しているデータ数: {len(missing_destination_indices)}\")\n",
    "\n",
    "# 2. 特徴量の選定\n",
    "destination_features = [\n",
    "    'HomePlanet', 'CryoSleep', 'Age', 'VIP',\n",
    "    'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'\n",
    "]\n",
    "\n",
    "print(f\"\\n--- Destination の補完に使用する特徴量候補 ---\")\n",
    "print(destination_features)\n",
    "\n",
    "# 3. モデル学習用データの準備 (Destination がわかっているデータ)\n",
    "non_null_destination_df = all_data[all_data['Destination'].notnull()].copy()\n",
    "print(f\"\\nDestination が非欠損のデータ数: {len(non_null_destination_df)}\")\n",
    "\n",
    "#    特徴量と目的変数の分離\n",
    "X_destination = non_null_destination_df[destination_features].copy()\n",
    "y_destination = non_null_destination_df['Destination'].copy() # object 型 (カテゴリ)\n",
    "\n",
    "# 4. 特徴量の前処理\n",
    "print(f\"\\n--- 特徴量の前処理 ---\")\n",
    "#    - カテゴリ変数の処理 (HomePlanet, CryoSleep)\n",
    "X_destination_processed = pd.get_dummies(X_destination, columns=['HomePlanet', 'CryoSleep'], dummy_na=True)\n",
    "\n",
    "#    - バイナリ変数の処理 (VIP)\n",
    "X_destination_processed['VIP'] = X_destination_processed['VIP'].fillna(False).astype(int)\n",
    "\n",
    "#    - 数値変数の欠損値処理\n",
    "numeric_cols_for_destination = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in numeric_cols_for_destination:\n",
    "    if col in X_destination_processed.columns:\n",
    "        X_destination_processed[col] = X_destination_processed[col].fillna(X_destination_processed[col].mean())\n",
    "\n",
    "# 5. モデルの定義と比較 (CPU モード)\n",
    "print(\"\\n=== Destination 補完モデルの定義 (CPU) ===\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "models_destination = {}\n",
    "\n",
    "# LightGBM (CPU)\n",
    "lgb_params_dest = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'metric': 'multi_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 100,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'device': 'cpu'\n",
    "}\n",
    "print(\"LightGBM: CPU 使用設定\")\n",
    "models_destination['LightGBM'] = lgb.LGBMClassifier(**lgb_params_dest)\n",
    "\n",
    "# XGBoost (CPU) - 修正箇所: LabelEncoder を使用\n",
    "xgb_params_dest = {\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 3,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'booster': 'gbtree',\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 100,\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "print(\"XGBoost: CPU 使用設定 (tree_method='hist') - LabelEncoder を使用\")\n",
    "# XGBoost 用のモデルは、後で y_destination を変換してから作成・評価します。\n",
    "\n",
    "# CatBoost (CPU)\n",
    "cb_params_dest = {\n",
    "    'loss_function': 'MultiClass',\n",
    "    'eval_metric': 'MultiClass',\n",
    "    'iterations': 100,\n",
    "    'depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "    'task_type': 'CPU'\n",
    "}\n",
    "print(\"CatBoost: CPU 使用設定\")\n",
    "models_destination['CatBoost'] = cb.CatBoostClassifier(**cb_params_dest)\n",
    "\n",
    "# RandomForest\n",
    "rf_params_dest = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "print(\"RandomForest: 設定\")\n",
    "models_destination['RandomForest'] = RandomForestClassifier(**rf_params_dest)\n",
    "\n",
    "# --- 6. モデル評価 (交差検証) ---\n",
    "print(\"\\n=== Destination モデル評価 (交差検証) ===\")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import time\n",
    "\n",
    "# 交差検証の設定\n",
    "cv_folds = 5\n",
    "skf_dest = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "scoring_metric_dest = 'accuracy'\n",
    "\n",
    "# XGBoost 用に LabelEncoder を準備\n",
    "le_dest = LabelEncoder()\n",
    "y_destination_encoded = le_dest.fit_transform(y_destination) # 文字列 -> 0, 1, 2\n",
    "\n",
    "model_scores_dest = {}\n",
    "model_times_dest = {}\n",
    "\n",
    "# LightGBM, CatBoost, RandomForest の評価 (元のラベル y_destination を使用)\n",
    "for name in ['LightGBM', 'CatBoost', 'RandomForest']:\n",
    "    model = models_destination[name]\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        scores = cross_val_score(model, X_destination_processed, y_destination, cv=skf_dest, scoring=scoring_metric_dest, n_jobs=1)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error during CV for {name}: {e}\")\n",
    "        model_scores_dest[name] = np.nan\n",
    "        model_times_dest[name] = time.time() - start_time\n",
    "        continue\n",
    "\n",
    "    end_time = time.time()\n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    model_scores_dest[name] = mean_score\n",
    "    model_times_dest[name] = elapsed_time\n",
    "    print(f\"  {name} - CV Accuracy: {mean_score:.5f} (+/- {std_score * 2:.5f}), Time: {elapsed_time:.2f}s\")\n",
    "\n",
    "# XGBoost の評価 (数値ラベル y_destination_encoded を使用)\n",
    "print(f\"Evaluating XGBoost...\")\n",
    "model_xgb_dest = xgb.XGBClassifier(**xgb_params_dest, enable_categorical=False)\n",
    "start_time = time.time()\n",
    "try:\n",
    "    scores = cross_val_score(model_xgb_dest, X_destination_processed, y_destination_encoded, cv=skf_dest, scoring=scoring_metric_dest, n_jobs=1)\n",
    "except Exception as e:\n",
    "    print(f\"  Error during CV for XGBoost: {e}\")\n",
    "    model_scores_dest['XGBoost'] = np.nan\n",
    "    model_times_dest['XGBoost'] = time.time() - start_time\n",
    "else:\n",
    "    end_time = time.time()\n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    model_scores_dest['XGBoost'] = mean_score\n",
    "    model_times_dest['XGBoost'] = elapsed_time\n",
    "    print(f\"  XGBoost - CV Accuracy: {mean_score:.5f} (+/- {std_score * 2:.5f}), Time: {elapsed_time:.2f}s\")\n",
    "\n",
    "# --- 7. 結果出力 ---\n",
    "print(\"\\n=== Destination モデル比較結果 (CV Accuracy) ===\")\n",
    "sorted_models_dest = sorted(\n",
    "    [(name, score) for name, score in model_scores_dest.items() if not np.isnan(score)],\n",
    "    key=lambda item: item[1], reverse=True\n",
    ")\n",
    "for name, score in sorted_models_dest:\n",
    "    print(f\"{name}: {score:.5f} (Time: {model_times_dest[name]:.2f}s)\")\n",
    "\n",
    "if sorted_models_dest:\n",
    "    best_model_name_dest, best_model_score_dest = sorted_models_dest[0]\n",
    "    print(f\"\\n--- Destination 補完に最も適したモデル: {best_model_name_dest} (CV Accuracy: {best_model_score_dest:.5f}) ---\")\n",
    "else:\n",
    "    print(\"\\n--- Destination モデル評価結果がありません ---\")\n",
    "    best_model_name_dest = None\n",
    "\n",
    "# 次のセルで、選ばれた最良モデルで実際に Destination の欠損値を補完します。\n",
    "# (セル 7 の内容)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8c8e80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Destination 欠損値補完の実行 ===\n",
      "Destination が欠損しているデータ数: 274\n",
      "\n",
      "=== Destination 補完モデル (CatBoost) の学習 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39046/207029085.py:36: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  features_for_prediction_dest_df['VIP'] = features_for_prediction_dest_df['VIP'].fillna(False).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習完了\n",
      "\n",
      "=== Destination 欠損値の予測 ===\n",
      "予測された Destination ラベル (最初の10件): [['TRAPPIST-1e']\n",
      " ['TRAPPIST-1e']\n",
      " ['TRAPPIST-1e']\n",
      " ['TRAPPIST-1e']\n",
      " ['TRAPPIST-1e']\n",
      " ['TRAPPIST-1e']\n",
      " ['TRAPPIST-1e']\n",
      " ['TRAPPIST-1e']\n",
      " ['TRAPPIST-1e']\n",
      " ['TRAPPIST-1e']]\n",
      "予測結果のデータ型: <class 'numpy.ndarray'>\n",
      "\n",
      "=== 補完結果の反映 ===\n",
      "Destination 列の欠損値が補完されました。\n",
      "\n",
      "補完後の全データを '../data/all_data_imputed_step3_Destination.csv' に保存しました。\n",
      "\n",
      "=== 次の補完対象カラム 'Age' の欠損状況 ===\n",
      "'Age' の欠損値数: 270\n"
     ]
    }
   ],
   "source": [
    "# --- 前提条件 ---\n",
    "# best_model_name_dest = 'CatBoost' (前セルの結果)\n",
    "# all_data は HomePlanet と CryoSleep が補完された状態\n",
    "# X_destination_processed, y_destination は前セルで定義済み (モデル学習用の特徴量と目的変数)\n",
    "# destination_features は前セルで定義済み (使用する特徴量のリスト)\n",
    "# models_destination は前セルで定義済み (モデル辞書)\n",
    "# le_dest は前セルで定義済み (LabelEncoder, XGBoost用だが今回は使わない)\n",
    "\n",
    "print(\"=== Destination 欠損値補完の実行 ===\")\n",
    "\n",
    "# 1. 補完対象データの特定 (Destination が欠損している行)\n",
    "missing_destination_mask = all_data['Destination'].isnull()\n",
    "missing_destination_indices = all_data[missing_destination_mask].index\n",
    "print(f\"Destination が欠損しているデータ数: {len(missing_destination_indices)}\")\n",
    "\n",
    "# 2. 補完に使用する特徴量の準備 (欠損行のみ)\n",
    "features_for_prediction_dest_df = all_data.loc[missing_destination_mask, destination_features].copy()\n",
    "\n",
    "# 3. 特徴量の前処理 (学習時と同様)\n",
    "#    - カテゴリ変数の処理 (HomePlanet, CryoSleep)\n",
    "features_for_prediction_dest_df = pd.get_dummies(features_for_prediction_dest_df, columns=['HomePlanet', 'CryoSleep'], dummy_na=True)\n",
    "\n",
    "#    - 学習データの One-Hot 後のカラムに合わせる\n",
    "#      `X_destination_processed` のカラムが基準\n",
    "for col in X_destination_processed.columns: # 学習時のカラム\n",
    "    if col not in features_for_prediction_dest_df.columns:\n",
    "        features_for_prediction_dest_df[col] = 0 # 学習時にあったが予測時にない列は0で追加\n",
    "for col in features_for_prediction_dest_df.columns:\n",
    "    if col not in X_destination_processed.columns:\n",
    "        features_for_prediction_dest_df.drop(columns=[col], inplace=True) # 予測時にあったが学習時にない列は削除\n",
    "\n",
    "#    - カラムの並び順を学習時と一致させる\n",
    "features_for_prediction_dest_df = features_for_prediction_dest_df[X_destination_processed.columns]\n",
    "\n",
    "#    - バイナリ変数の処理 (VIP)\n",
    "features_for_prediction_dest_df['VIP'] = features_for_prediction_dest_df['VIP'].fillna(False).astype(int)\n",
    "\n",
    "#    - 数値変数の欠損値処理 (学習データの平均値で補完 - モデル入力用)\n",
    "#      重要: 学習データ X_destination_processed の平均値を使う！\n",
    "numeric_cols_for_destination = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in numeric_cols_for_destination:\n",
    "    if col in features_for_prediction_dest_df.columns:\n",
    "        # 学習データの平均値を取得\n",
    "        train_mean = X_destination_processed[col].mean()\n",
    "        features_for_prediction_dest_df[col] = features_for_prediction_dest_df[col].fillna(train_mean)\n",
    "\n",
    "# 4. モデルの学習 (評価済みの best_model_name_dest が 'CatBoost' であることを前提)\n",
    "print(f\"\\n=== Destination 補完モデル ({best_model_name_dest}) の学習 ===\")\n",
    "# 評価時に使用した X_destination_processed, y_destination を使って最終モデルを学習\n",
    "final_imputer_model_dest = models_destination[best_model_name_dest] # models_destination は前セルで定義済み\n",
    "final_imputer_model_dest.fit(X_destination_processed, y_destination) # CatBoost は文字列ラベル y_destination をそのまま使える\n",
    "print(\"学習完了\")\n",
    "\n",
    "# 5. 欠損値の予測\n",
    "print(\"\\n=== Destination 欠損値の予測 ===\")\n",
    "predicted_destinations = final_imputer_model_dest.predict(features_for_prediction_dest_df)\n",
    "# 予測結果は文字列ラベル (例: 'TRAPPIST-1e') であることを確認\n",
    "print(f\"予測された Destination ラベル (最初の10件): {predicted_destinations[:10]}\")\n",
    "print(f\"予測結果のデータ型: {type(predicted_destinations[0])}\") # 各要素の型を確認\n",
    "\n",
    "# 6. 元のデータフレームに補完結果を反映\n",
    "print(\"\\n=== 補完結果の反映 ===\")\n",
    "# 予測結果 (文字列配列) を直接代入\n",
    "all_data.loc[missing_destination_indices, 'Destination'] = predicted_destinations\n",
    "print(\"Destination 列の欠損値が補完されました。\")\n",
    "\n",
    "# 7. 新しいCSVファイルへの保存\n",
    "# ファイルパスの確認と作成 (必要に応じて)\n",
    "import os\n",
    "data_dir = \"../data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    print(f\"ディレクトリ '{data_dir}' を作成しました。\")\n",
    "\n",
    "output_file_path_dest = os.path.join(data_dir, 'all_data_imputed_step3_Destination.csv')\n",
    "all_data.to_csv(output_file_path_dest, index=False)\n",
    "print(f\"\\n補完後の全データを '{output_file_path_dest}' に保存しました。\")\n",
    "\n",
    "# 8. 次のステップへの準備\n",
    "# 次は Age です。その前に、データの状態を確認します。\n",
    "print(f\"\\n=== 次の補完対象カラム 'Age' の欠損状況 ===\")\n",
    "print(f\"'Age' の欠損値数: {all_data['Age'].isnull().sum()}\")\n",
    "\n",
    "# 次のステップでは、'Age' の補完モデルを作成・評価します。\n",
    "# Destination の補完結果も特徴量として使用できます。\n",
    "# 次のセル (セル 8) で進めていきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90bd1915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Age 欠損値補完の準備 ===\n",
      "Age が欠損しているデータ数: 270\n",
      "\n",
      "--- Age の補完に使用する特徴量候補 ---\n",
      "['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
      "\n",
      "Age が非欠損のデータ数: 12700\n",
      "\n",
      "--- 特徴量の前処理 ---\n",
      "\n",
      "=== Age 補完モデルの定義 (CPU) ===\n",
      "LightGBM Regressor: CPU 使用設定\n",
      "XGBoost Regressor: CPU 使用設定 (tree_method='hist')\n",
      "CatBoost Regressor: CPU 使用設定\n",
      "RandomForest Regressor: 設定\n",
      "\n",
      "=== Age モデル評価 (交差検証) ===\n",
      "Evaluating LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39046/2300592329.py:42: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_age_processed['VIP'] = X_age_processed['VIP'].fillna(False).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  LightGBM - CV RMSE: 13.09 (+/- 0.38), Time: 0.35s\n",
      "Evaluating XGBoost...\n",
      "  XGBoost - CV RMSE: 13.14 (+/- 0.37), Time: 12.90s\n",
      "Evaluating CatBoost...\n",
      "  CatBoost - CV RMSE: 13.10 (+/- 0.36), Time: -10.95s\n",
      "Evaluating RandomForest...\n",
      "  RandomForest - CV RMSE: 13.11 (+/- 0.37), Time: 0.85s\n",
      "\n",
      "=== Age モデル比較結果 (CV RMSE - 小さいほど良い) ===\n",
      "LightGBM: RMSE=13.09 (Time: 0.35s)\n",
      "CatBoost: RMSE=13.10 (Time: -10.95s)\n",
      "RandomForest: RMSE=13.11 (Time: 0.85s)\n",
      "XGBoost: RMSE=13.14 (Time: 12.90s)\n",
      "\n",
      "--- Age 補完に最も適したモデル: LightGBM (CV RMSE: 13.09) ---\n"
     ]
    }
   ],
   "source": [
    "# --- 前提条件 ---\n",
    "# all_data は HomePlanet, CryoSleep, Destination が補完された状態 (../data/all_data_imputed_step3_Destination.csv から読み込み済み or メモリ上)\n",
    "# ここでは all_data が既に更新されている前提\n",
    "\n",
    "print(\"=== Age 欠損値補完の準備 ===\")\n",
    "\n",
    "# 1. 補完対象データの特定 (Age が欠損している行)\n",
    "missing_age_mask = all_data['Age'].isnull()\n",
    "missing_age_indices = all_data[missing_age_mask].index\n",
    "print(f\"Age が欠損しているデータ数: {len(missing_age_indices)}\")\n",
    "\n",
    "# 2. 特徴量の選定 (Age 予測に使えそうなもの)\n",
    "#    これまで補完した HomePlanet, CryoSleep, Destination も特徴量に含めます。\n",
    "#    Cabin は Deck/Side 分解が有効かもしれませんが、まずは文字列全体 or 分解版 (後で追加も可)。\n",
    "#    Name, PassengerId は一旦除外します。\n",
    "#    消費金額も特徴量に含めます。\n",
    "age_features = [\n",
    "    'HomePlanet', 'CryoSleep', 'Destination', 'VIP',\n",
    "    'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'\n",
    "    # 'Cabin' # 後で Deck/Side に分解して追加検討\n",
    "]\n",
    "\n",
    "print(f\"\\n--- Age の補完に使用する特徴量候補 ---\")\n",
    "print(age_features)\n",
    "\n",
    "# 3. モデル学習用データの準備 (Age がわかっているデータ)\n",
    "non_null_age_df = all_data[all_data['Age'].notnull()].copy()\n",
    "print(f\"\\nAge が非欠損のデータ数: {len(non_null_age_df)}\")\n",
    "\n",
    "#    特徴量と目的変数の分離\n",
    "X_age = non_null_age_df[age_features].copy()\n",
    "y_age = non_null_age_df['Age'].copy() # float64 型 (数値)\n",
    "\n",
    "# 4. 特徴量の前処理\n",
    "print(f\"\\n--- 特徴量の前処理 ---\")\n",
    "#    - カテゴリ変数の処理 (HomePlanet, CryoSleep, Destination)\n",
    "#      One-Hot Encoding を使用します。\n",
    "X_age_processed = pd.get_dummies(X_age, columns=['HomePlanet', 'CryoSleep', 'Destination'], dummy_na=True)\n",
    "\n",
    "#    - バイナリ変数の処理 (VIP)\n",
    "#      欠損値は False として扱います。\n",
    "X_age_processed['VIP'] = X_age_processed['VIP'].fillna(False).astype(int)\n",
    "\n",
    "#    - 数値変数の欠損値処理 (RoomService, FoodCourt, ShoppingMall, Spa, VRDeck)\n",
    "#      学習データの平均値で補完します。\n",
    "numeric_cols_for_age = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in numeric_cols_for_age:\n",
    "    if col in X_age_processed.columns: # 存在する場合のみ処理\n",
    "        X_age_processed[col] = X_age_processed[col].fillna(X_age_processed[col].mean())\n",
    "\n",
    "# 5. モデルの定義と比較 (CPU モード)\n",
    "#    Age は数値 (回帰) です。\n",
    "print(\"\\n=== Age 補完モデルの定義 (CPU) ===\")\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.metrics import mean_squared_error # 回帰の評価指標\n",
    "\n",
    "models_age = {}\n",
    "\n",
    "# LightGBM Regressor (CPU)\n",
    "lgb_params_age = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse', # 回帰の評価指標\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 100,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'device': 'cpu'\n",
    "}\n",
    "print(\"LightGBM Regressor: CPU 使用設定\")\n",
    "models_age['LightGBM'] = lgb.LGBMRegressor(**lgb_params_age)\n",
    "\n",
    "# XGBoost Regressor (CPU)\n",
    "xgb_params_age = {\n",
    "    'objective': 'reg:squarederror', # 回帰 (二乗誤差)\n",
    "    'eval_metric': 'rmse', # 内部評価指標\n",
    "    'booster': 'gbtree',\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 100,\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "print(\"XGBoost Regressor: CPU 使用設定 (tree_method='hist')\")\n",
    "models_age['XGBoost'] = xgb.XGBRegressor(**xgb_params_age, enable_categorical=False) # OneHot済みなのでFalse\n",
    "\n",
    "# CatBoost Regressor (CPU)\n",
    "cb_params_age = {\n",
    "    'loss_function': 'RMSE', # 回帰の損失関数\n",
    "    'eval_metric': 'RMSE',\n",
    "    'iterations': 100,\n",
    "    'depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "    'task_type': 'CPU'\n",
    "}\n",
    "print(\"CatBoost Regressor: CPU 使用設定\")\n",
    "models_age['CatBoost'] = cb.CatBoostRegressor(**cb_params_age)\n",
    "\n",
    "# RandomForest Regressor\n",
    "rf_params_age = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "print(\"RandomForest Regressor: 設定\")\n",
    "models_age['RandomForest'] = RandomForestRegressor(**rf_params_age)\n",
    "\n",
    "# --- 6. モデル評価 (交差検証) ---\n",
    "print(\"\\n=== Age モデル評価 (交差検証) ===\")\n",
    "from sklearn.model_selection import KFold, cross_val_score # 回帰なので KFold\n",
    "import time\n",
    "\n",
    "# 交差検証の設定 (回帰用)\n",
    "cv_folds = 5\n",
    "kf_age = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "# 回帰の評価指標: RMSE (Root Mean Squared Error) の符号を反転させたもの (neg_root_mean_squared_error)\n",
    "# sklearn に neg_root_mean_squared_error がない場合、neg_mean_squared_error の平方根を取る\n",
    "scoring_metric_age = 'neg_mean_squared_error' # または 'r2' (決定係数) も選択可\n",
    "\n",
    "model_scores_age = {}\n",
    "model_times_age = {}\n",
    "\n",
    "for name, model in models_age.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        # n_jobs=1 にして、並列処理によるトラブルを避ける\n",
    "        scores = cross_val_score(model, X_age_processed, y_age, cv=kf_age, scoring=scoring_metric_age, n_jobs=1)\n",
    "        # scores は負のMSE。RMSEにするには sqrt(-score) が必要。\n",
    "        # ただし、cross_val_score の結果は平均と標準偏差の比較にそのまま使える。\n",
    "        rmse_scores = np.sqrt(-scores)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error during CV for {name}: {e}\")\n",
    "        # エラーが発生した場合はスコアを None とする\n",
    "        model_scores_age[name] = np.nan\n",
    "        model_times_age[name] = time.time() - start_time\n",
    "        continue\n",
    "\n",
    "    end_time = time.time()\n",
    "    mean_rmse = rmse_scores.mean()\n",
    "    std_rmse = rmse_scores.std()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    model_scores_age[name] = mean_rmse # RMSEの平均を格納\n",
    "    model_times_age[name] = elapsed_time\n",
    "\n",
    "    print(f\"  {name} - CV RMSE: {mean_rmse:.2f} (+/- {std_rmse * 2:.2f}), Time: {elapsed_time:.2f}s\")\n",
    "\n",
    "# --- 7. 結果出力 ---\n",
    "print(\"\\n=== Age モデル比較結果 (CV RMSE - 小さいほど良い) ===\")\n",
    "# NaN を除外してソート (RMSEが小さい方が良いので reverse=False)\n",
    "sorted_models_age = sorted(\n",
    "    [(name, score) for name, score in model_scores_age.items() if not np.isnan(score)],\n",
    "    key=lambda item: item[1], reverse=False # RMSE が小さいほど良い\n",
    ")\n",
    "for name, score in sorted_models_age:\n",
    "    print(f\"{name}: RMSE={score:.2f} (Time: {model_times_age[name]:.2f}s)\")\n",
    "\n",
    "if sorted_models_age:\n",
    "    best_model_name_age, best_model_score_age = sorted_models_age[0]\n",
    "    print(f\"\\n--- Age 補完に最も適したモデル: {best_model_name_age} (CV RMSE: {best_model_score_age:.2f}) ---\")\n",
    "else:\n",
    "    print(\"\\n--- Age モデル評価結果がありません ---\")\n",
    "    best_model_name_age = None\n",
    "\n",
    "# 次のセルで、選ばれた最良モデルで実際に Age の欠損値を補完します。\n",
    "# (セル 9 の内容をここに書くか、次のセルに分割するかはお任せします)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d91b9370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Age 欠損値補完の実行 ===\n",
      "Age が欠損しているデータ数: 270\n",
      "\n",
      "=== Age 補完モデル (LightGBM) の学習 ===\n",
      "学習完了\n",
      "\n",
      "=== Age 欠損値の予測 ===\n",
      "予測された Age (最初の10件): [29.15730817 31.50955197 21.12326613 35.52049528 38.17648676 32.54892812\n",
      " 21.69404638 25.94347926 37.13202953 28.1504719 ]\n",
      "予測結果のデータ型: float64\n",
      "\n",
      "=== 補完結果の反映 ===\n",
      "Age 列の欠損値が補完されました。\n",
      "\n",
      "補完後の全データを '../data/all_data_imputed_step4_Age.csv' に保存しました。\n",
      "\n",
      "=== 次の補完対象カラム 'VIP' の欠損状況 ===\n",
      "'VIP' の欠損値数: 296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39046/1547524564.py:35: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  features_for_prediction_age_df['VIP'] = features_for_prediction_age_df['VIP'].fillna(False).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# --- 前提条件 ---\n",
    "# best_model_name_age = 'LightGBM' (前セルの結果)\n",
    "# all_data は HomePlanet, CryoSleep, Destination が補完された状態\n",
    "# X_age_processed, y_age は前セルで定義済み (モデル学習用の特徴量と目的変数)\n",
    "# age_features は前セルで定義済み (使用する特徴量のリスト)\n",
    "# models_age は前セルで定義済み (モデル辞書)\n",
    "\n",
    "print(\"=== Age 欠損値補完の実行 ===\")\n",
    "\n",
    "# 1. 補完対象データの特定 (Age が欠損している行)\n",
    "missing_age_mask = all_data['Age'].isnull()\n",
    "missing_age_indices = all_data[missing_age_mask].index\n",
    "print(f\"Age が欠損しているデータ数: {len(missing_age_indices)}\")\n",
    "\n",
    "# 2. 補完に使用する特徴量の準備 (欠損行のみ)\n",
    "features_for_prediction_age_df = all_data.loc[missing_age_mask, age_features].copy()\n",
    "\n",
    "# 3. 特徴量の前処理 (学習時と同様)\n",
    "#    - カテゴリ変数の処理 (HomePlanet, CryoSleep, Destination)\n",
    "features_for_prediction_age_df = pd.get_dummies(features_for_prediction_age_df, columns=['HomePlanet', 'CryoSleep', 'Destination'], dummy_na=True)\n",
    "\n",
    "#    - 学習データの One-Hot 後のカラムに合わせる\n",
    "#      `X_age_processed` のカラムが基準\n",
    "for col in X_age_processed.columns: # 学習時のカラム\n",
    "    if col not in features_for_prediction_age_df.columns:\n",
    "        features_for_prediction_age_df[col] = 0 # 学習時にあったが予測時にない列は0で追加\n",
    "for col in features_for_prediction_age_df.columns:\n",
    "    if col not in X_age_processed.columns:\n",
    "        features_for_prediction_age_df.drop(columns=[col], inplace=True) # 予測時にあったが学習時にない列は削除\n",
    "\n",
    "#    - カラムの並び順を学習時と一致させる\n",
    "features_for_prediction_age_df = features_for_prediction_age_df[X_age_processed.columns]\n",
    "\n",
    "#    - バイナリ変数の処理 (VIP)\n",
    "features_for_prediction_age_df['VIP'] = features_for_prediction_age_df['VIP'].fillna(False).astype(int)\n",
    "\n",
    "#    - 数値変数の欠損値処理 (学習データの平均値で補完 - モデル入力用)\n",
    "#      重要: 学習データ X_age_processed の平均値を使う！\n",
    "numeric_cols_for_age = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in numeric_cols_for_age:\n",
    "    if col in features_for_prediction_age_df.columns:\n",
    "        # 学習データの平均値を取得\n",
    "        train_mean = X_age_processed[col].mean()\n",
    "        features_for_prediction_age_df[col] = features_for_prediction_age_df[col].fillna(train_mean)\n",
    "\n",
    "# 4. モデルの学習 (評価済みの best_model_name_age が 'LightGBM' であることを前提)\n",
    "print(f\"\\n=== Age 補完モデル ({best_model_name_age}) の学習 ===\")\n",
    "# 評価時に使用した X_age_processed, y_age を使って最終モデルを学習\n",
    "final_imputer_model_age = models_age[best_model_name_age] # models_age は前セルで定義済み\n",
    "final_imputer_model_age.fit(X_age_processed, y_age) # LightGBM Regressor は数値 y_age をそのまま使える\n",
    "print(\"学習完了\")\n",
    "\n",
    "# 5. 欠損値の予測\n",
    "print(\"\\n=== Age 欠損値の予測 ===\")\n",
    "predicted_ages = final_imputer_model_age.predict(features_for_prediction_age_df)\n",
    "# 予測結果は数値 (float) の配列であることを確認\n",
    "print(f\"予測された Age (最初の10件): {predicted_ages[:10]}\")\n",
    "print(f\"予測結果のデータ型: {predicted_ages.dtype}\")\n",
    "\n",
    "# 6. 元のデータフレームに補完結果を反映\n",
    "print(\"\\n=== 補完結果の反映 ===\")\n",
    "# 予測結果 (数値配列) を直接代入\n",
    "all_data.loc[missing_age_indices, 'Age'] = predicted_ages\n",
    "print(\"Age 列の欠損値が補完されました。\")\n",
    "\n",
    "# 7. 新しいCSVファイルへの保存\n",
    "# ファイルパスの確認と作成 (必要に応じて)\n",
    "import os\n",
    "data_dir = \"../data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    print(f\"ディレクトリ '{data_dir}' を作成しました。\")\n",
    "\n",
    "output_file_path_age = os.path.join(data_dir, 'all_data_imputed_step4_Age.csv')\n",
    "all_data.to_csv(output_file_path_age, index=False)\n",
    "print(f\"\\n補完後の全データを '{output_file_path_age}' に保存しました。\")\n",
    "\n",
    "# 8. 次のステップへの準備\n",
    "# 次は VIP です。その前に、データの状態を確認します。\n",
    "print(f\"\\n=== 次の補完対象カラム 'VIP' の欠損状況 ===\")\n",
    "print(f\"'VIP' の欠損値数: {all_data['VIP'].isnull().sum()}\")\n",
    "\n",
    "# 次のステップでは、'VIP' の補完モデルを作成・評価します。\n",
    "# Age の補完結果も特徴量として使用できます。\n",
    "# 次のセル (セル 10) で進めていきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "968e0d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VIP 欠損値補完の準備 ===\n",
      "VIP が欠損しているデータ数: 296\n",
      "\n",
      "--- VIP の補完に使用する特徴量候補 ---\n",
      "['HomePlanet', 'CryoSleep', 'Destination', 'Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
      "\n",
      "VIP が非欠損のデータ数: 12674\n",
      "\n",
      "--- y_vip のデータ型確認 ---\n",
      "y_vip の dtype: object\n",
      "y_vip のユニーク値: [False True]\n",
      "y_vip を object から bool に変換しました。\n",
      "変換後の dtype: bool\n",
      "変換後のユニーク値: [False  True]\n",
      "\n",
      "--- 特徴量の前処理 ---\n",
      "\n",
      "=== VIP 補完モデルの定義 (CPU) ===\n",
      "LightGBM: CPU 使用設定\n",
      "XGBoost: CPU 使用設定 (tree_method='hist')\n",
      "CatBoost: CPU 使用設定\n",
      "RandomForest: 設定\n",
      "\n",
      "=== VIP モデル評価 (交差検証) ===\n",
      "Evaluating LightGBM...\n",
      "  LightGBM - CV Accuracy: 0.97862 (+/- 0.00105), Time: 0.35s\n",
      "Evaluating XGBoost...\n",
      "  XGBoost - CV Accuracy: 0.97901 (+/- 0.00153), Time: 0.76s\n",
      "Evaluating CatBoost...\n",
      "  CatBoost - CV Accuracy: 0.97846 (+/- 0.00038), Time: 13.69s\n",
      "Evaluating RandomForest...\n",
      "  RandomForest - CV Accuracy: 0.97909 (+/- 0.00086), Time: -11.50s\n",
      "\n",
      "=== VIP モデル比較結果 (CV Accuracy) ===\n",
      "RandomForest: 0.97909 (Time: -11.50s)\n",
      "XGBoost: 0.97901 (Time: 0.76s)\n",
      "LightGBM: 0.97862 (Time: 0.35s)\n",
      "CatBoost: 0.97846 (Time: 13.69s)\n",
      "\n",
      "--- VIP 補完に最も適したモデル: RandomForest (CV Accuracy: 0.97909) ---\n"
     ]
    }
   ],
   "source": [
    "# --- 前提条件 ---\n",
    "# all_data は HomePlanet, CryoSleep, Destination, Age が補完された状態 (../data/all_data_imputed_step4_Age.csv から読み込み済み or メモリ上)\n",
    "# ここでは all_data が既に更新されている前提\n",
    "\n",
    "print(\"=== VIP 欠損値補完の準備 ===\")\n",
    "\n",
    "# 1. 補完対象データの特定 (VIP が欠損している行)\n",
    "missing_vip_mask = all_data['VIP'].isnull()\n",
    "missing_vip_indices = all_data[missing_vip_mask].index\n",
    "print(f\"VIP が欠損しているデータ数: {len(missing_vip_indices)}\")\n",
    "\n",
    "# 2. 特徴量の選定 (VIP 予測に使えそうなもの)\n",
    "#    これまで補完した HomePlanet, CryoSleep, Destination, Age も特徴量に含めます。\n",
    "#    Cabin は Deck/Side 分解が有効かもしれませんが、まずは文字列全体 or 分解版 (後で追加も可)。\n",
    "#    Name, PassengerId は一旦除外します。\n",
    "#    消費金額も特徴量に含めます。\n",
    "vip_features = [\n",
    "    'HomePlanet', 'CryoSleep', 'Destination', 'Age',\n",
    "    'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'\n",
    "    # 'Cabin' # 後で Deck/Side に分解して追加検討\n",
    "]\n",
    "\n",
    "print(f\"\\n--- VIP の補完に使用する特徴量候補 ---\")\n",
    "print(vip_features)\n",
    "\n",
    "# 3. モデル学習用データの準備 (VIP がわかっているデータ)\n",
    "non_null_vip_df = all_data[all_data['VIP'].notnull()].copy()\n",
    "print(f\"\\nVIP が非欠損のデータ数: {len(non_null_vip_df)}\")\n",
    "\n",
    "#    特徴量と目的変数の分離\n",
    "X_vip = non_null_vip_df[vip_features].copy()\n",
    "y_vip = non_null_vip_df['VIP'].copy() # object 型 (bool または 'True'/'False' 文字列)\n",
    "\n",
    "# --- 重要な追加: y_vip のデータ型を確認・修正 ---\n",
    "print(f\"\\n--- y_vip のデータ型確認 ---\")\n",
    "print(f\"y_vip の dtype: {y_vip.dtype}\")\n",
    "print(f\"y_vip のユニーク値: {y_vip.unique()}\")\n",
    "\n",
    "# データ型が bool でない場合、明示的に変換\n",
    "if y_vip.dtype == 'object':\n",
    "    # object 型の場合、True/False/'True'/'False' などを bool に変換\n",
    "    y_vip = y_vip.map({'True': True, 'False': False, True: True, False: False})\n",
    "    print(f\"y_vip を object から bool に変換しました。\")\n",
    "    print(f\"変換後の dtype: {y_vip.dtype}\")\n",
    "    print(f\"変換後のユニーク値: {y_vip.unique()}\")\n",
    "elif y_vip.dtype != 'bool':\n",
    "    # その他の型の場合も、念のため変換を試みる\n",
    "    try:\n",
    "        y_vip = y_vip.astype(bool)\n",
    "        print(f\"y_vip を {y_vip.dtype} から bool に変換しました。\")\n",
    "    except (ValueError, TypeError) as e:\n",
    "        print(f\"y_vip の型変換中にエラーが発生しました: {e}\")\n",
    "        print(\"モデル評価を続行できません。\")\n",
    "        raise # エラーを再送出して処理を停止\n",
    "\n",
    "# 4. 特徴量の前処理\n",
    "print(f\"\\n--- 特徴量の前処理 ---\")\n",
    "#    - カテゴリ変数の処理 (HomePlanet, CryoSleep, Destination)\n",
    "#      One-Hot Encoding を使用します。\n",
    "X_vip_processed = pd.get_dummies(X_vip, columns=['HomePlanet', 'CryoSleep', 'Destination'], dummy_na=True)\n",
    "\n",
    "#    - 数値変数の欠損値処理 (Age, RoomService, FoodCourt, ShoppingMall, Spa, VRDeck)\n",
    "#      学習データの平均値で補完します。\n",
    "numeric_cols_for_vip = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in numeric_cols_for_vip:\n",
    "    if col in X_vip_processed.columns: # 存在する場合のみ処理\n",
    "        X_vip_processed[col] = X_vip_processed[col].fillna(X_vip_processed[col].mean())\n",
    "\n",
    "#    - XGBoost など一部モデルのために、VIP の前処理で発生した object 型を int に変換する可能性のある処理は不要\n",
    "#      (すでに y_vip が bool になっているため)\n",
    "\n",
    "# 5. モデルの定義と比較 (CPU モード)\n",
    "#    VIP は bool (True/False) なので、二値分類 (Binary Classification) です。\n",
    "print(\"\\n=== VIP 補完モデルの定義 (CPU) ===\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "models_vip = {}\n",
    "\n",
    "# LightGBM (CPU)\n",
    "lgb_params_vip = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 100,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'device': 'cpu'\n",
    "}\n",
    "print(\"LightGBM: CPU 使用設定\")\n",
    "models_vip['LightGBM'] = lgb.LGBMClassifier(**lgb_params_vip)\n",
    "\n",
    "# XGBoost (CPU)\n",
    "# 注意: y_vip が bool なので、XGBoost でも問題ありません。\n",
    "#       LabelEncoder は不要です。\n",
    "xgb_params_vip = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'booster': 'gbtree',\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 100,\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "print(\"XGBoost: CPU 使用設定 (tree_method='hist')\")\n",
    "models_vip['XGBoost'] = xgb.XGBClassifier(**xgb_params_vip, enable_categorical=False) # OneHot済みなのでFalse\n",
    "\n",
    "# CatBoost (CPU)\n",
    "cb_params_vip = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'Logloss',\n",
    "    'iterations': 100,\n",
    "    'depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "    'task_type': 'CPU'\n",
    "}\n",
    "print(\"CatBoost: CPU 使用設定\")\n",
    "models_vip['CatBoost'] = cb.CatBoostClassifier(**cb_params_vip)\n",
    "\n",
    "# RandomForest\n",
    "rf_params_vip = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "print(\"RandomForest: 設定\")\n",
    "models_vip['RandomForest'] = RandomForestClassifier(**rf_params_vip)\n",
    "\n",
    "# --- 6. モデル評価 (交差検証) ---\n",
    "print(\"\\n=== VIP モデル評価 (交差検証) ===\")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import time\n",
    "\n",
    "# 交差検証の設定\n",
    "cv_folds = 5\n",
    "skf_vip = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "scoring_metric_vip = 'accuracy' # 二値分類の正解率\n",
    "\n",
    "model_scores_vip = {}\n",
    "model_times_vip = {}\n",
    "\n",
    "for name, model in models_vip.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        # n_jobs=1 にして、並列処理によるトラブルを避ける\n",
    "        scores = cross_val_score(model, X_vip_processed, y_vip, cv=skf_vip, scoring=scoring_metric_vip, n_jobs=1)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error during CV for {name}: {e}\")\n",
    "        # エラーが発生した場合はスコアを None とする\n",
    "        model_scores_vip[name] = np.nan\n",
    "        model_times_vip[name] = time.time() - start_time\n",
    "        continue\n",
    "\n",
    "    end_time = time.time()\n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    model_scores_vip[name] = mean_score\n",
    "    model_times_vip[name] = elapsed_time\n",
    "\n",
    "    print(f\"  {name} - CV Accuracy: {mean_score:.5f} (+/- {std_score * 2:.5f}), Time: {elapsed_time:.2f}s\")\n",
    "\n",
    "# --- 7. 結果出力 ---\n",
    "print(\"\\n=== VIP モデル比較結果 (CV Accuracy) ===\")\n",
    "# NaN を除外してソート\n",
    "sorted_models_vip = sorted(\n",
    "    [(name, score) for name, score in model_scores_vip.items() if not np.isnan(score)],\n",
    "    key=lambda item: item[1], reverse=True\n",
    ")\n",
    "for name, score in sorted_models_vip:\n",
    "    print(f\"{name}: {score:.5f} (Time: {model_times_vip[name]:.2f}s)\")\n",
    "\n",
    "if sorted_models_vip:\n",
    "    best_model_name_vip, best_model_score_vip = sorted_models_vip[0]\n",
    "    print(f\"\\n--- VIP 補完に最も適したモデル: {best_model_name_vip} (CV Accuracy: {best_model_score_vip:.5f}) ---\")\n",
    "else:\n",
    "    print(\"\\n--- VIP モデル評価結果がありません ---\")\n",
    "    best_model_name_vip = None\n",
    "\n",
    "# 次のセルで、選ばれた最良モデルで実際に VIP の欠損値を補完します。\n",
    "# (セル 11 の内容)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "061ee482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VIP 欠損値補完の実行 ===\n",
      "VIP が欠損しているデータ数: 296\n",
      "\n",
      "=== VIP 補完モデル (RandomForest) の学習 ===\n",
      "学習完了\n",
      "\n",
      "=== VIP 欠損値の予測 ===\n",
      "予測された VIP ラベル (最初の10件): [False False False False False False False False False False]\n",
      "予測結果のデータ型: bool\n",
      "\n",
      "=== 補完結果の反映 ===\n",
      "VIP 列の欠損値が補完されました。\n",
      "\n",
      "補完後の全データを '../data/all_data_imputed_step5_VIP.csv' に保存しました。\n",
      "\n",
      "=== 次の補完対象カラム 'Cabin' の欠損状況 ===\n",
      "'Cabin' の欠損値数: 299\n"
     ]
    }
   ],
   "source": [
    "# --- 前提条件 ---\n",
    "# best_model_name_vip = 'RandomForest' (前セルの結果)\n",
    "# all_data は HomePlanet, CryoSleep, Destination, Age が補完された状態\n",
    "# X_vip_processed, y_vip は前セルで定義済み (モデル学習用の特徴量と目的変数)\n",
    "# vip_features は前セルで定義済み (使用する特徴量のリスト)\n",
    "# models_vip は前セルで定義済み (モデル辞書)\n",
    "\n",
    "print(\"=== VIP 欠損値補完の実行 ===\")\n",
    "\n",
    "# 1. 補完対象データの特定 (VIP が欠損している行)\n",
    "missing_vip_mask = all_data['VIP'].isnull()\n",
    "missing_vip_indices = all_data[missing_vip_mask].index\n",
    "print(f\"VIP が欠損しているデータ数: {len(missing_vip_indices)}\")\n",
    "\n",
    "# 2. 補完に使用する特徴量の準備 (欠損行のみ)\n",
    "features_for_prediction_vip_df = all_data.loc[missing_vip_mask, vip_features].copy()\n",
    "\n",
    "# 3. 特徴量の前処理 (学習時と同様)\n",
    "#    - カテゴリ変数の処理 (HomePlanet, CryoSleep, Destination)\n",
    "features_for_prediction_vip_df = pd.get_dummies(features_for_prediction_vip_df, columns=['HomePlanet', 'CryoSleep', 'Destination'], dummy_na=True)\n",
    "\n",
    "#    - 学習データの One-Hot 後のカラムに合わせる\n",
    "#      `X_vip_processed` のカラムが基準\n",
    "for col in X_vip_processed.columns: # 学習時のカラム\n",
    "    if col not in features_for_prediction_vip_df.columns:\n",
    "        features_for_prediction_vip_df[col] = 0 # 学習時にあったが予測時にない列は0で追加\n",
    "for col in features_for_prediction_vip_df.columns:\n",
    "    if col not in X_vip_processed.columns:\n",
    "        features_for_prediction_vip_df.drop(columns=[col], inplace=True) # 予測時にあったが学習時にない列は削除\n",
    "\n",
    "#    - カラムの並び順を学習時と一致させる\n",
    "features_for_prediction_vip_df = features_for_prediction_vip_df[X_vip_processed.columns]\n",
    "\n",
    "#    - 数値変数の欠損値処理 (学習データの平均値で補完 - モデル入力用)\n",
    "#      重要: 学習データ X_vip_processed の平均値を使う！\n",
    "numeric_cols_for_vip = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in numeric_cols_for_vip:\n",
    "    if col in features_for_prediction_vip_df.columns:\n",
    "        # 学習データの平均値を取得\n",
    "        train_mean = X_vip_processed[col].mean()\n",
    "        features_for_prediction_vip_df[col] = features_for_prediction_vip_df[col].fillna(train_mean)\n",
    "\n",
    "# 4. モデルの学習 (評価済みの best_model_name_vip が 'RandomForest' であることを前提)\n",
    "print(f\"\\n=== VIP 補完モデル ({best_model_name_vip}) の学習 ===\")\n",
    "# 評価時に使用した X_vip_processed, y_vip を使って最終モデルを学習\n",
    "final_imputer_model_vip = models_vip[best_model_name_vip] # models_vip は前セルで定義済み\n",
    "final_imputer_model_vip.fit(X_vip_processed, y_vip) # RandomForest は bool ラベル y_vip をそのまま使える\n",
    "print(\"学習完了\")\n",
    "\n",
    "# 5. 欠損値の予測\n",
    "print(\"\\n=== VIP 欠損値の予測 ===\")\n",
    "predicted_vips = final_imputer_model_vip.predict(features_for_prediction_vip_df)\n",
    "# 予測結果は bool 型 (True/False) であることを確認\n",
    "print(f\"予測された VIP ラベル (最初の10件): {predicted_vips[:10]}\")\n",
    "print(f\"予測結果のデータ型: {predicted_vips.dtype}\")\n",
    "\n",
    "# 6. 元のデータフレームに補完結果を反映\n",
    "print(\"\\n=== 補完結果の反映 ===\")\n",
    "# 予測結果 (bool 配列) を直接代入\n",
    "all_data.loc[missing_vip_indices, 'VIP'] = predicted_vips\n",
    "print(\"VIP 列の欠損値が補完されました。\")\n",
    "\n",
    "# 7. 新しいCSVファイルへの保存\n",
    "# ファイルパスの確認と作成 (必要に応じて)\n",
    "import os\n",
    "data_dir = \"../data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    print(f\"ディレクトリ '{data_dir}' を作成しました。\")\n",
    "\n",
    "output_file_path_vip = os.path.join(data_dir, 'all_data_imputed_step5_VIP.csv')\n",
    "all_data.to_csv(output_file_path_vip, index=False)\n",
    "print(f\"\\n補完後の全データを '{output_file_path_vip}' に保存しました。\")\n",
    "\n",
    "# 8. 次のステップへの準備\n",
    "# 次は Cabin です。その前に、データの状態を確認します。\n",
    "# 注意: Cabin は文字列で、Deck/Side に分解する必要があります。\n",
    "print(f\"\\n=== 次の補完対象カラム 'Cabin' の欠損状況 ===\")\n",
    "print(f\"'Cabin' の欠損値数: {all_data['Cabin'].isnull().sum()}\")\n",
    "\n",
    "# 次のステップでは、'Cabin' の補完モデルを作成・評価します。\n",
    "# まず、Cabin を Deck と Side に分解する前処理が必要です。\n",
    "# 次のセル (セル 12) で進めていきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2dc3d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cabin 欠損値補完の準備 ===\n",
      "Cabin 列を Deck と Side に分解しました。\n",
      "Deck のユニーク値: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T']\n",
      "Side のユニーク値: ['P', 'S']\n",
      "\n",
      "--- Deck/Side の欠損状況 ---\n",
      "Deck の欠損値数: 299\n",
      "Side の欠損値数: 299\n",
      "\n",
      "==================== Deck の補完 ====================\n",
      "Deck が欠損しているデータ数: 299\n",
      "\n",
      "--- Deck の補完に使用する特徴量候補 ---\n",
      "['HomePlanet', 'CryoSleep', 'Destination', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
      "\n",
      "Deck が非欠損のデータ数: 12671\n",
      "\n",
      "--- Deck 特徴量の前処理 ---\n",
      "  データ型変換前 (Deck):\n",
      "bool       11\n",
      "float64     6\n",
      "object      1\n",
      "Name: count, dtype: int64\n",
      "  Deck: VIP 列を int に変換しました。\n",
      "  データ型変換後 (Deck):\n",
      "bool       11\n",
      "float64     6\n",
      "int64       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Deck 補完モデルの定義 (CPU) ===\n",
      "LightGBM: CPU 使用設定\n",
      "XGBoost: CPU 使用設定 (tree_method='hist') - LabelEncoder を使用\n",
      "CatBoost: CPU 使用設定\n",
      "RandomForest: 設定\n",
      "\n",
      "=== Deck モデル評価 (交差検証) ===\n",
      "Evaluating LightGBM (Deck)...\n",
      "  LightGBM (Deck) - CV Accuracy: 0.63144 (+/- 0.01189), Time: 1.95s\n",
      "Evaluating CatBoost (Deck)...\n",
      "  CatBoost (Deck) - CV Accuracy: 0.62797 (+/- 0.00932), Time: 2.60s\n",
      "Evaluating RandomForest (Deck)...\n",
      "  RandomForest (Deck) - CV Accuracy: 0.62986 (+/- 0.01002), Time: 0.86s\n",
      "Evaluating XGBoost (Deck)...\n",
      "  XGBoost (Deck) - CV Accuracy: 0.63499 (+/- 0.00893), Time: 2.46s\n",
      "\n",
      "=== Deck モデル比較結果 (CV Accuracy) ===\n",
      "XGBoost: 0.63499 (Time: 2.46s)\n",
      "LightGBM: 0.63144 (Time: 1.95s)\n",
      "RandomForest: 0.62986 (Time: 0.86s)\n",
      "CatBoost: 0.62797 (Time: 2.60s)\n",
      "\n",
      "--- Deck 補完に最も適したモデル: XGBoost (CV Accuracy: 0.63499) ---\n",
      "\n",
      "==================== Side の補完 ====================\n",
      "Side が欠損しているデータ数: 299\n",
      "\n",
      "--- Side の補完に使用する特徴量候補 ---\n",
      "['HomePlanet', 'CryoSleep', 'Destination', 'Age', 'VIP', 'Deck', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
      "\n",
      "Side が非欠損のデータ数: 12671\n",
      "\n",
      "--- Side 特徴量の前処理 ---\n",
      "  データ型変換前 (Side):\n",
      "bool       20\n",
      "float64     6\n",
      "object      1\n",
      "Name: count, dtype: int64\n",
      "  Side: VIP 列を int に変換しました。\n",
      "  データ型変換後 (Side):\n",
      "bool       20\n",
      "float64     6\n",
      "int64       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Side 補完モデルの定義 (CPU) ===\n",
      "LightGBM: CPU 使用設定\n",
      "XGBoost: CPU 使用設定 (tree_method='hist')\n",
      "CatBoost: CPU 使用設定\n",
      "RandomForest: 設定\n",
      "\n",
      "=== Side モデル評価 (交差検証) ===\n",
      "Evaluating LightGBM (Side)...\n",
      "  LightGBM (Side) - CV Accuracy: 0.50533 (+/- 0.01456), Time: 0.31s\n",
      "Evaluating CatBoost (Side)...\n",
      "  CatBoost (Side) - CV Accuracy: 0.50762 (+/- 0.00843), Time: 1.96s\n",
      "Evaluating RandomForest (Side)...\n",
      "  RandomForest (Side) - CV Accuracy: 0.51125 (+/- 0.01179), Time: 13.25s\n",
      "Evaluating XGBoost (Side)...\n",
      "  XGBoost (Side) - CV Accuracy: 0.50114 (+/- 0.01310), Time: -11.49s\n",
      "\n",
      "=== Side モデル比較結果 (CV Accuracy) ===\n",
      "RandomForest: 0.51125 (Time: 13.25s)\n",
      "CatBoost: 0.50762 (Time: 1.96s)\n",
      "LightGBM: 0.50533 (Time: 0.31s)\n",
      "XGBoost: 0.50114 (Time: -11.49s)\n",
      "\n",
      "--- Side 補完に最も適したモデル: RandomForest (CV Accuracy: 0.51125) ---\n",
      "\n",
      "=== 次のステップへの準備 ===\n",
      "Deck と Side のモデル比較が完了しました。\n",
      "次は、選ばれたモデルを使って Deck と Side の欠損値を実際に補完し、Cabin を再構成します。\n",
      "その後、消費金額 (RoomService, FoodCourt, ...) の補完に進みます。\n",
      "次のセル (セル 13) で進めていきましょう。\n"
     ]
    }
   ],
   "source": [
    "# --- 前提条件 ---\n",
    "# all_data は HomePlanet, CryoSleep, Destination, Age, VIP が補完された状態\n",
    "# ここでは all_data が既に更新されている前提\n",
    "\n",
    "print(\"=== Cabin 欠損値補完の準備 ===\")\n",
    "\n",
    "# 1. Cabin 列の Feature Engineering: Deck と Side に分解\n",
    "def extract_deck(cabin_str):\n",
    "    if pd.isna(cabin_str) or cabin_str == '':\n",
    "        return np.nan\n",
    "    return cabin_str.split('/')[0]\n",
    "\n",
    "def extract_side(cabin_str):\n",
    "    if pd.isna(cabin_str) or cabin_str == '':\n",
    "        return np.nan\n",
    "    parts = cabin_str.split('/')\n",
    "    if len(parts) >= 3:\n",
    "        return parts[2]\n",
    "    else:\n",
    "        return np.nan  # 形式が正しくない場合は NaN\n",
    "\n",
    "# Deck と Side を抽出\n",
    "all_data['Deck'] = all_data['Cabin'].apply(extract_deck)\n",
    "all_data['Side'] = all_data['Cabin'].apply(extract_side)\n",
    "\n",
    "print(\"Cabin 列を Deck と Side に分解しました。\")\n",
    "print(f\"Deck のユニーク値: {sorted(all_data['Deck'].dropna().unique())}\")\n",
    "print(f\"Side のユニーク値: {sorted(all_data['Side'].dropna().unique())}\")\n",
    "\n",
    "# 2. Deck と Side の欠損状況確認\n",
    "print(f\"\\n--- Deck/Side の欠損状況 ---\")\n",
    "print(f\"Deck の欠損値数: {all_data['Deck'].isnull().sum()}\")\n",
    "print(f\"Side の欠損値数: {all_data['Side'].isnull().sum()}\")\n",
    "\n",
    "# --- Deck の補完 ---\n",
    "print(\"\\n\" + \"=\"*20 + \" Deck の補完 \" + \"=\"*20)\n",
    "\n",
    "# 3. Deck 補完対象データの特定\n",
    "missing_deck_mask = all_data['Deck'].isnull()\n",
    "missing_deck_indices = all_data[missing_deck_mask].index\n",
    "print(f\"Deck が欠損しているデータ数: {len(missing_deck_indices)}\")\n",
    "\n",
    "# 4. 特徴量の選定\n",
    "deck_features = [\n",
    "    'HomePlanet', 'CryoSleep', 'Destination', 'Age', 'VIP',\n",
    "    'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'\n",
    "]\n",
    "\n",
    "print(f\"\\n--- Deck の補完に使用する特徴量候補 ---\")\n",
    "print(deck_features)\n",
    "\n",
    "# 5. モデル学習用データの準備 (Deck がわかっているデータ)\n",
    "non_null_deck_df = all_data[all_data['Deck'].notnull()].copy()\n",
    "print(f\"\\nDeck が非欠損のデータ数: {len(non_null_deck_df)}\")\n",
    "\n",
    "# 特徴量と目的変数の分離\n",
    "X_deck = non_null_deck_df[deck_features].copy()\n",
    "y_deck = non_null_deck_df['Deck'].copy()  # object 型 (カテゴリ)\n",
    "\n",
    "# 6. 特徴量の前処理 (Deck)\n",
    "print(f\"\\n--- Deck 特徴量の前処理 ---\")\n",
    "# - カテゴリ変数の処理 (HomePlanet, CryoSleep, Destination)\n",
    "X_deck_processed = pd.get_dummies(X_deck, columns=['HomePlanet', 'CryoSleep', 'Destination'], dummy_na=True)\n",
    "\n",
    "# --- 重要な修正: データ型の確認と変換 (Deck) ---\n",
    "print(\"  データ型変換前 (Deck):\")\n",
    "print(X_deck_processed.dtypes.value_counts())\n",
    "\n",
    "# VIP が object になっている可能性があるため int に変換\n",
    "if 'VIP' in X_deck_processed.columns:\n",
    "    # object 型 (True/False or 'True'/'False') -> bool -> int\n",
    "    X_deck_processed['VIP'] = X_deck_processed['VIP'].map({'True': True, 'False': False, True: True, False: False})\n",
    "    X_deck_processed['VIP'] = X_deck_processed['VIP'].astype(int)\n",
    "    print(\"  Deck: VIP 列を int に変換しました。\")\n",
    "\n",
    "# 数値変数の欠損値処理\n",
    "numeric_cols_for_deck = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in numeric_cols_for_deck:\n",
    "    if col in X_deck_processed.columns:\n",
    "        X_deck_processed[col] = X_deck_processed[col].fillna(X_deck_processed[col].mean())\n",
    "\n",
    "print(\"  データ型変換後 (Deck):\")\n",
    "print(X_deck_processed.dtypes.value_counts())\n",
    "# --- これで Deck の特徴量はすべて適切な型 (int/float) になったはず ---\n",
    "\n",
    "\n",
    "# 7. Deck モデルの定義と比較 (CPU モード)\n",
    "print(\"\\n=== Deck 補完モデルの定義 (CPU) ===\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "models_deck = {}\n",
    "\n",
    "# LightGBM (CPU)\n",
    "lgb_params_deck = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(y_deck.dropna().unique()),  # Deck のクラス数 (NaNを除く)\n",
    "    'metric': 'multi_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 100,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'device': 'cpu'\n",
    "}\n",
    "print(\"LightGBM: CPU 使用設定\")\n",
    "models_deck['LightGBM'] = lgb.LGBMClassifier(**lgb_params_deck)\n",
    "\n",
    "# XGBoost (CPU) - LabelEncoder を使用\n",
    "xgb_params_deck = {\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': len(y_deck.dropna().unique()),\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'booster': 'gbtree',\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 100,\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "print(\"XGBoost: CPU 使用設定 (tree_method='hist') - LabelEncoder を使用\")\n",
    "# XGBoostモデルを作成し models_deck に登録\n",
    "models_deck['XGBoost'] = xgb.XGBClassifier(**xgb_params_deck, enable_categorical=False)\n",
    "\n",
    "# CatBoost (CPU)\n",
    "cb_params_deck = {\n",
    "    'loss_function': 'MultiClass',\n",
    "    'eval_metric': 'MultiClass',\n",
    "    'iterations': 100,\n",
    "    'depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "    'task_type': 'CPU'\n",
    "}\n",
    "print(\"CatBoost: CPU 使用設定\")\n",
    "models_deck['CatBoost'] = cb.CatBoostClassifier(**cb_params_deck)\n",
    "\n",
    "# RandomForest\n",
    "rf_params_deck = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "print(\"RandomForest: 設定\")\n",
    "models_deck['RandomForest'] = RandomForestClassifier(**rf_params_deck)\n",
    "\n",
    "# 8. Deck モデル評価 (交差検証)\n",
    "print(\"\\n=== Deck モデル評価 (交差検証) ===\")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import time\n",
    "\n",
    "# 交差検証の設定\n",
    "cv_folds = 5\n",
    "skf_deck = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "scoring_metric_deck = 'accuracy'\n",
    "\n",
    "# XGBoost 用に LabelEncoder を準備\n",
    "le_deck = LabelEncoder()\n",
    "y_deck_encoded = le_deck.fit_transform(y_deck)  # 文字列 -> 0, 1, 2, ...\n",
    "\n",
    "model_scores_deck = {}\n",
    "model_times_deck = {}\n",
    "\n",
    "# LightGBM, CatBoost, RandomForest の評価 (元のラベル y_deck を使用)\n",
    "for name in ['LightGBM', 'CatBoost', 'RandomForest']:\n",
    "    model = models_deck[name]\n",
    "    print(f\"Evaluating {name} (Deck)...\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        scores = cross_val_score(model, X_deck_processed, y_deck, cv=skf_deck, scoring=scoring_metric_deck, n_jobs=1)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error during CV for {name} (Deck): {e}\")\n",
    "        model_scores_deck[name] = np.nan\n",
    "        model_times_deck[name] = time.time() - start_time\n",
    "        continue\n",
    "\n",
    "    end_time = time.time()\n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    model_scores_deck[name] = mean_score\n",
    "    model_times_deck[name] = elapsed_time\n",
    "    print(f\"  {name} (Deck) - CV Accuracy: {mean_score:.5f} (+/- {std_score * 2:.5f}), Time: {elapsed_time:.2f}s\")\n",
    "\n",
    "# XGBoost の評価 (数値ラベル y_deck_encoded を使用)\n",
    "print(f\"Evaluating XGBoost (Deck)...\")\n",
    "model_xgb_deck = models_deck['XGBoost']\n",
    "start_time = time.time()\n",
    "try:\n",
    "    scores = cross_val_score(model_xgb_deck, X_deck_processed, y_deck_encoded, cv=skf_deck, scoring=scoring_metric_deck, n_jobs=1)\n",
    "except Exception as e:\n",
    "    print(f\"  Error during CV for XGBoost (Deck): {e}\")\n",
    "    model_scores_deck['XGBoost'] = np.nan\n",
    "    model_times_deck['XGBoost'] = time.time() - start_time\n",
    "else:\n",
    "    end_time = time.time()\n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    model_scores_deck['XGBoost'] = mean_score\n",
    "    model_times_deck['XGBoost'] = elapsed_time\n",
    "    print(f\"  XGBoost (Deck) - CV Accuracy: {mean_score:.5f} (+/- {std_score * 2:.5f}), Time: {elapsed_time:.2f}s\")\n",
    "\n",
    "# --- 9. Deck モデル比較結果 ---\n",
    "print(\"\\n=== Deck モデル比較結果 (CV Accuracy) ===\")\n",
    "sorted_models_deck = sorted(\n",
    "    [(name, score) for name, score in model_scores_deck.items() if not np.isnan(score)],\n",
    "    key=lambda item: item[1], reverse=True\n",
    ")\n",
    "for name, score in sorted_models_deck:\n",
    "    print(f\"{name}: {score:.5f} (Time: {model_times_deck[name]:.2f}s)\")\n",
    "\n",
    "if sorted_models_deck:\n",
    "    # --- 重要: 最優秀モデル名を変数に格納 ---\n",
    "    best_model_name_deck, best_model_score_deck = sorted_models_deck[0]\n",
    "    print(f\"\\n--- Deck 補完に最も適したモデル: {best_model_name_deck} (CV Accuracy: {best_model_score_deck:.5f}) ---\")\n",
    "else:\n",
    "    print(\"\\n--- Deck モデル評価結果がありません ---\")\n",
    "    best_model_name_deck = None\n",
    "\n",
    "\n",
    "# --- Side の補完 ---\n",
    "print(\"\\n\" + \"=\"*20 + \" Side の補完 \" + \"=\"*20)\n",
    "\n",
    "# 10. Side 補完対象データの特定\n",
    "missing_side_mask = all_data['Side'].isnull()\n",
    "missing_side_indices = all_data[missing_side_mask].index\n",
    "print(f\"Side が欠損しているデータ数: {len(missing_side_indices)}\")\n",
    "\n",
    "# 11. 特徴量の選定\n",
    "# Deck は先ほど求めた Deck 列を使用 (Deck 補完前の欠損値も含む)\n",
    "side_features = [\n",
    "    'HomePlanet', 'CryoSleep', 'Destination', 'Age', 'VIP', 'Deck',\n",
    "    'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck'\n",
    "]\n",
    "\n",
    "print(f\"\\n--- Side の補完に使用する特徴量候補 ---\")\n",
    "print(side_features)\n",
    "\n",
    "# 12. モデル学習用データの準備 (Side がわかっているデータ)\n",
    "non_null_side_df = all_data[all_data['Side'].notnull()].copy()\n",
    "print(f\"\\nSide が非欠損のデータ数: {len(non_null_side_df)}\")\n",
    "\n",
    "# 特徴量と目的変数の分離\n",
    "X_side = non_null_side_df[side_features].copy()\n",
    "y_side = non_null_side_df['Side'].copy()  # object 型 (カテゴリ: 'P' or 'S')\n",
    "\n",
    "# 13. 特徴量の前処理 (Side)\n",
    "print(f\"\\n--- Side 特徴量の前処理 ---\")\n",
    "# - カテゴリ変数の処理 (HomePlanet, CryoSleep, Destination, Deck)\n",
    "X_side_processed = pd.get_dummies(X_side, columns=['HomePlanet', 'CryoSleep', 'Destination', 'Deck'], dummy_na=True)\n",
    "\n",
    "# --- 重要な修正: データ型の確認と変換 (Side) ---\n",
    "print(\"  データ型変換前 (Side):\")\n",
    "print(X_side_processed.dtypes.value_counts())\n",
    "\n",
    "# VIP が object になっている可能性があるため int に変換\n",
    "if 'VIP' in X_side_processed.columns:\n",
    "    X_side_processed['VIP'] = X_side_processed['VIP'].map({'True': True, 'False': False, True: True, False: False})\n",
    "    X_side_processed['VIP'] = X_side_processed['VIP'].astype(int)\n",
    "    print(\"  Side: VIP 列を int に変換しました。\")\n",
    "\n",
    "# 数値変数の欠損値処理\n",
    "numeric_cols_for_side = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in numeric_cols_for_side:\n",
    "    if col in X_side_processed.columns:\n",
    "        X_side_processed[col] = X_side_processed[col].fillna(X_side_processed[col].mean())\n",
    "\n",
    "print(\"  データ型変換後 (Side):\")\n",
    "print(X_side_processed.dtypes.value_counts())\n",
    "# --- これで Side の特徴量はすべて適切な型 (int/float) になったはず ---\n",
    "\n",
    "\n",
    "# 14. Side モデルの定義と比較 (CPU モード)\n",
    "print(\"\\n=== Side 補完モデルの定義 (CPU) ===\")\n",
    "\n",
    "models_side = {}\n",
    "\n",
    "# LightGBM (CPU)\n",
    "lgb_params_side = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 100,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'device': 'cpu'\n",
    "}\n",
    "print(\"LightGBM: CPU 使用設定\")\n",
    "models_side['LightGBM'] = lgb.LGBMClassifier(**lgb_params_side)\n",
    "\n",
    "# XGBoost (CPU)\n",
    "xgb_params_side = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'booster': 'gbtree',\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 100,\n",
    "    'random_state': 42,\n",
    "    'tree_method': 'hist'\n",
    "}\n",
    "print(\"XGBoost: CPU 使用設定 (tree_method='hist')\")\n",
    "models_side['XGBoost'] = xgb.XGBClassifier(**xgb_params_side, enable_categorical=False)\n",
    "\n",
    "# CatBoost (CPU)\n",
    "cb_params_side = {\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'Logloss',\n",
    "    'iterations': 100,\n",
    "    'depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "    'task_type': 'CPU'\n",
    "}\n",
    "print(\"CatBoost: CPU 使用設定\")\n",
    "models_side['CatBoost'] = cb.CatBoostClassifier(**cb_params_side)\n",
    "\n",
    "# RandomForest\n",
    "rf_params_side = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "print(\"RandomForest: 設定\")\n",
    "models_side['RandomForest'] = RandomForestClassifier(**rf_params_side)\n",
    "\n",
    "# 15. Side モデル評価 (交差検証)\n",
    "print(\"\\n=== Side モデル評価 (交差検証) ===\")\n",
    "\n",
    "cv_folds = 5\n",
    "skf_side = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "scoring_metric_side = 'accuracy'  # 二値分類の正解率\n",
    "\n",
    "model_scores_side = {}\n",
    "model_times_side = {}\n",
    "\n",
    "# XGBoost以外のモデルを通常通り評価\n",
    "for name, model in models_side.items():\n",
    "    if name == 'XGBoost':\n",
    "        continue  # XGBoostは後で別処理する\n",
    "    print(f\"Evaluating {name} (Side)...\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        scores = cross_val_score(model, X_side_processed, y_side, cv=skf_side, scoring=scoring_metric_side, n_jobs=1)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error during CV for {name} (Side): {e}\")\n",
    "        model_scores_side[name] = np.nan\n",
    "        model_times_side[name] = time.time() - start_time\n",
    "        continue\n",
    "\n",
    "    end_time = time.time()\n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    model_scores_side[name] = mean_score\n",
    "    model_times_side[name] = elapsed_time\n",
    "    print(f\"  {name} (Side) - CV Accuracy: {mean_score:.5f} (+/- {std_score * 2:.5f}), Time: {elapsed_time:.2f}s\")\n",
    "\n",
    "# --- Side の XGBoost 評価修正版 (数値ラベル対応) ---\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_side = LabelEncoder()\n",
    "y_side_encoded = le_side.fit_transform(y_side)  # 'P'->0, 'S'->1\n",
    "\n",
    "print(f\"Evaluating XGBoost (Side)...\")\n",
    "model_xgb_side = models_side['XGBoost']\n",
    "start_time = time.time()\n",
    "try:\n",
    "    # XGBoost にはエンコードされた y_side_encoded を渡す\n",
    "    scores = cross_val_score(model_xgb_side, X_side_processed, y_side_encoded, cv=skf_side, scoring=scoring_metric_side, n_jobs=1)\n",
    "except Exception as e:\n",
    "    print(f\"  Error during CV for XGBoost (Side): {e}\")\n",
    "    model_scores_side['XGBoost'] = np.nan\n",
    "    model_times_side['XGBoost'] = time.time() - start_time\n",
    "else:\n",
    "    end_time = time.time()\n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    model_scores_side['XGBoost'] = mean_score\n",
    "    model_times_side['XGBoost'] = elapsed_time\n",
    "    print(f\"  XGBoost (Side) - CV Accuracy: {mean_score:.5f} (+/- {std_score * 2:.5f}), Time: {elapsed_time:.2f}s\")\n",
    "\n",
    "# --- 16. Side モデル比較結果 ---\n",
    "print(\"\\n=== Side モデル比較結果 (CV Accuracy) ===\")\n",
    "sorted_models_side = sorted(\n",
    "    [(name, score) for name, score in model_scores_side.items() if not np.isnan(score)],\n",
    "    key=lambda item: item[1], reverse=True\n",
    ")\n",
    "for name, score in sorted_models_side:\n",
    "    print(f\"{name}: {score:.5f} (Time: {model_times_side[name]:.2f}s)\")\n",
    "\n",
    "if sorted_models_side:\n",
    "    # --- 重要: 最優秀モデル名を変数に格納 ---\n",
    "    best_model_name_side, best_model_score_side = sorted_models_side[0]\n",
    "    print(f\"\\n--- Side 補完に最も適したモデル: {best_model_name_side} (CV Accuracy: {best_model_score_side:.5f}) ---\")\n",
    "else:\n",
    "    print(\"\\n--- Side モデル評価結果がありません ---\")\n",
    "    best_model_name_side = None\n",
    "\n",
    "# --- 17. 次のステップへの準備 ---\n",
    "print(f\"\\n=== 次のステップへの準備 ===\")\n",
    "print(\"Deck と Side のモデル比較が完了しました。\")\n",
    "print(\"次は、選ばれたモデルを使って Deck と Side の欠損値を実際に補完し、Cabin を再構成します。\")\n",
    "print(\"その後、消費金額 (RoomService, FoodCourt, ...) の補完に進みます。\")\n",
    "print(\"次のセル (セル 13) で進めていきましょう。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54af3a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 必要な変数の確認 ===\n",
      "best_model_name_deck: XGBoost\n",
      "best_model_name_side: RandomForest\n",
      "models_deck のキー: ['LightGBM', 'XGBoost', 'CatBoost', 'RandomForest']\n",
      "models_side のキー: ['LightGBM', 'XGBoost', 'CatBoost', 'RandomForest']\n",
      "すべての必要な変数が確認されました。\n",
      "\n",
      "=== Deck と Side の欠損値補完の実行 ===\n",
      "\n",
      "--- Deck の欠損値補完 ---\n",
      "Deck が欠損しているデータ数: 299\n",
      "  予測用データの VIP 列を int に変換しました。\n",
      "  Deck 補完モデル (XGBoost) の取得と学習...\n",
      "  Deck モデル (XGBoost) 学習完了 (エンコード済みラベル使用)\n",
      "  Deck 欠損値の予測...\n",
      "  予測された Deck ラベル (最初の10件): ['F' 'F' 'C' 'F' 'F' 'F' 'B' 'G' 'C' 'F']\n",
      "  Deck 列の欠損値が補完されました。\n",
      "\n",
      "--- Side の欠損値補完 ---\n",
      "Side が欠損しているデータ数: 299\n",
      "  予測用データの VIP 列を int に変換しました。\n",
      "  Side 補完モデル (RandomForest) の取得と学習...\n",
      "  Side モデル (RandomForest) 学習完了\n",
      "  Side 欠損値の予測...\n",
      "  予測された Side ラベル (最初の10件): ['P' 'S' 'S' 'P' 'S' 'S' 'S' 'S' 'S' 'P']\n",
      "  Side 列の欠損値が補完されました。\n",
      "\n",
      "--- Cabin 列の再構成 ---\n",
      "  Cabin 列を再構成した行数: 299\n",
      "\n",
      "--- 新しいCSVファイルへの保存 ---\n",
      "  補完後の全データを '../data/all_data_imputed_step6_Cabin.csv' に保存しました。\n",
      "\n",
      "=== 次のステップへの準備 ===\n",
      "  'RoomService' の欠損値数: 263\n",
      "  'FoodCourt' の欠損値数: 289\n",
      "  'ShoppingMall' の欠損値数: 306\n",
      "  'Spa' の欠損値数: 284\n",
      "  'VRDeck' の欠損値数: 268\n",
      "\n",
      "次は、これらの消費金額列の欠損値を回帰モデルで補完します。\n"
     ]
    }
   ],
   "source": [
    "# --- 変数存在確認コード ---\n",
    "required_vars = ['best_model_name_deck', 'best_model_name_side', 'models_deck', 'models_side', 'le_deck']\n",
    "missing_vars = [var for var in required_vars if var not in globals()]\n",
    "if missing_vars:\n",
    "    raise NameError(f\"必要な変数が定義されていません: {missing_vars}. セル12を先に実行してください。\")\n",
    "else:\n",
    "    print(\"=== 必要な変数の確認 ===\")\n",
    "    print(f\"best_model_name_deck: {best_model_name_deck}\")\n",
    "    print(f\"best_model_name_side: {best_model_name_side}\")\n",
    "    print(f\"models_deck のキー: {list(models_deck.keys())}\")\n",
    "    print(f\"models_side のキー: {list(models_side.keys())}\")\n",
    "    if best_model_name_deck not in models_deck:\n",
    "        raise KeyError(f\"models_deck に '{best_model_name_deck}' というキーがありません。\")\n",
    "    if best_model_name_side not in models_side:\n",
    "        raise KeyError(f\"models_side に '{best_model_name_side}' というキーがありません。\")\n",
    "    print(\"すべての必要な変数が確認されました。\")\n",
    "\n",
    "print(\"\\n=== Deck と Side の欠損値補完の実行 ===\")\n",
    "\n",
    "# --- Deck の欠損値補完 ---\n",
    "print(\"\\n--- Deck の欠損値補完 ---\")\n",
    "missing_deck_mask = all_data['Deck'].isnull()\n",
    "missing_deck_indices = all_data[missing_deck_mask].index\n",
    "print(f\"Deck が欠損しているデータ数: {len(missing_deck_indices)}\")\n",
    "\n",
    "features_for_prediction_deck_df = all_data.loc[missing_deck_mask, deck_features].copy()\n",
    "features_for_prediction_deck_df = pd.get_dummies(features_for_prediction_deck_df, columns=['HomePlanet', 'CryoSleep', 'Destination'], dummy_na=True)\n",
    "\n",
    "for col in X_deck_processed.columns:\n",
    "    if col not in features_for_prediction_deck_df.columns:\n",
    "        features_for_prediction_deck_df[col] = 0\n",
    "for col in features_for_prediction_deck_df.columns:\n",
    "    if col not in X_deck_processed.columns:\n",
    "        features_for_prediction_deck_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "features_for_prediction_deck_df = features_for_prediction_deck_df[X_deck_processed.columns]\n",
    "\n",
    "if 'VIP' in features_for_prediction_deck_df.columns:\n",
    "    features_for_prediction_deck_df['VIP'] = features_for_prediction_deck_df['VIP'].map({'True': True, 'False': False, True: True, False: False})\n",
    "    features_for_prediction_deck_df['VIP'] = features_for_prediction_deck_df['VIP'].astype(int)\n",
    "    print(\"  予測用データの VIP 列を int に変換しました。\")\n",
    "\n",
    "numeric_cols_for_deck = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in numeric_cols_for_deck:\n",
    "    if col in features_for_prediction_deck_df.columns:\n",
    "        train_mean = X_deck_processed[col].mean()\n",
    "        features_for_prediction_deck_df[col] = features_for_prediction_deck_df[col].fillna(train_mean)\n",
    "\n",
    "print(f\"  Deck 補完モデル ({best_model_name_deck}) の取得と学習...\")\n",
    "try:\n",
    "    final_imputer_model_deck = models_deck[best_model_name_deck]\n",
    "except KeyError as e:\n",
    "    raise KeyError(f\"models_deck に '{best_model_name_deck}' というキーがありません。セル12が正しく実行され、変数が定義されているか確認してください。\") from e\n",
    "\n",
    "if best_model_name_deck == 'XGBoost':\n",
    "    try:\n",
    "        final_imputer_model_deck.fit(X_deck_processed, le_deck.transform(y_deck))\n",
    "        print(\"  Deck モデル (XGBoost) 学習完了 (エンコード済みラベル使用)\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Deck XGBoost モデルの学習中にエラーが発生しました: {e}\") from e\n",
    "elif best_model_name_deck in ['LightGBM', 'CatBoost', 'RandomForest']:\n",
    "    try:\n",
    "        final_imputer_model_deck.fit(X_deck_processed, y_deck)\n",
    "        print(f\"  Deck モデル ({best_model_name_deck}) 学習完了 (文字列ラベル使用)\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Deck {best_model_name_deck} モデルの学習中にエラーが発生しました: {e}\") from e\n",
    "else:\n",
    "    raise ValueError(f\"未対応の Deck モデル: {best_model_name_deck}\")\n",
    "\n",
    "print(\"  Deck 欠損値の予測...\")\n",
    "try:\n",
    "    if best_model_name_deck == 'XGBoost':\n",
    "        predicted_decks_encoded = final_imputer_model_deck.predict(features_for_prediction_deck_df)\n",
    "        predicted_decks = le_deck.inverse_transform(predicted_decks_encoded)\n",
    "    else:\n",
    "        predicted_decks = final_imputer_model_deck.predict(features_for_prediction_deck_df)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Deck モデルの予測中にエラーが発生しました: {e}\") from e\n",
    "\n",
    "print(f\"  予測された Deck ラベル (最初の10件): {predicted_decks[:10]}\")\n",
    "all_data.loc[missing_deck_indices, 'Deck'] = predicted_decks\n",
    "print(\"  Deck 列の欠損値が補完されました。\")\n",
    "\n",
    "# --- Side の欠損値補完 ---\n",
    "print(\"\\n--- Side の欠損値補完 ---\")\n",
    "missing_side_mask = all_data['Side'].isnull()\n",
    "missing_side_indices = all_data[missing_side_mask].index\n",
    "print(f\"Side が欠損しているデータ数: {len(missing_side_indices)}\")\n",
    "\n",
    "features_for_prediction_side_df = all_data.loc[missing_side_mask, side_features].copy()\n",
    "features_for_prediction_side_df = pd.get_dummies(features_for_prediction_side_df, columns=['HomePlanet', 'CryoSleep', 'Destination', 'Deck'], dummy_na=True)\n",
    "\n",
    "for col in X_side_processed.columns:\n",
    "    if col not in features_for_prediction_side_df.columns:\n",
    "        features_for_prediction_side_df[col] = 0\n",
    "for col in features_for_prediction_side_df.columns:\n",
    "    if col not in X_side_processed.columns:\n",
    "        features_for_prediction_side_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "features_for_prediction_side_df = features_for_prediction_side_df[X_side_processed.columns]\n",
    "\n",
    "if 'VIP' in features_for_prediction_side_df.columns:\n",
    "    features_for_prediction_side_df['VIP'] = features_for_prediction_side_df['VIP'].map({'True': True, 'False': False, True: True, False: False})\n",
    "    features_for_prediction_side_df['VIP'] = features_for_prediction_side_df['VIP'].astype(int)\n",
    "    print(\"  予測用データの VIP 列を int に変換しました。\")\n",
    "\n",
    "numeric_cols_for_side = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in numeric_cols_for_side:\n",
    "    if col in features_for_prediction_side_df.columns:\n",
    "        train_mean = X_side_processed[col].mean()\n",
    "        features_for_prediction_side_df[col] = features_for_prediction_side_df[col].fillna(train_mean)\n",
    "\n",
    "print(f\"  Side 補完モデル ({best_model_name_side}) の取得と学習...\")\n",
    "try:\n",
    "    final_imputer_model_side = models_side[best_model_name_side]\n",
    "except KeyError as e:\n",
    "    raise KeyError(f\"models_side に '{best_model_name_side}' というキーがありません。セル12が正しく実行され、変数が定義されているか確認してください。\") from e\n",
    "\n",
    "if best_model_name_side in ['LightGBM', 'XGBoost', 'CatBoost', 'RandomForest']:\n",
    "    try:\n",
    "        final_imputer_model_side.fit(X_side_processed, y_side)\n",
    "        print(f\"  Side モデル ({best_model_name_side}) 学習完了\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Side {best_model_name_side} モデルの学習中にエラーが発生しました: {e}\") from e\n",
    "else:\n",
    "    raise ValueError(f\"未対応の Side モデル: {best_model_name_side}\")\n",
    "\n",
    "print(\"  Side 欠損値の予測...\")\n",
    "try:\n",
    "    predicted_sides = final_imputer_model_side.predict(features_for_prediction_side_df)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Side モデルの予測中にエラーが発生しました: {e}\") from e\n",
    "\n",
    "print(f\"  予測された Side ラベル (最初の10件): {predicted_sides[:10]}\")\n",
    "all_data.loc[missing_side_indices, 'Side'] = predicted_sides\n",
    "print(\"  Side 列の欠損値が補完されました。\")\n",
    "\n",
    "# --- Cabin 列の再構成 ---\n",
    "print(\"\\n--- Cabin 列の再構成 ---\")\n",
    "cabin_reconstruct_mask = all_data['Cabin'].isnull() & all_data['Deck'].notnull() & all_data['Side'].notnull()\n",
    "all_data.loc[cabin_reconstruct_mask, 'Cabin'] = (\n",
    "    all_data.loc[cabin_reconstruct_mask, 'Deck'].astype(str) + '/0/' +\n",
    "    all_data.loc[cabin_reconstruct_mask, 'Side'].astype(str)\n",
    ")\n",
    "print(f\"  Cabin 列を再構成した行数: {cabin_reconstruct_mask.sum()}\")\n",
    "\n",
    "# --- 新しいCSVファイルへの保存 ---\n",
    "print(\"\\n--- 新しいCSVファイルへの保存 ---\")\n",
    "import os\n",
    "data_dir = \"../data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    print(f\"  ディレクトリ '{data_dir}' を作成しました。\")\n",
    "\n",
    "output_file_path_cabin = os.path.join(data_dir, 'all_data_imputed_step6_Cabin.csv')\n",
    "all_data.to_csv(output_file_path_cabin, index=False)\n",
    "print(f\"  補完後の全データを '{output_file_path_cabin}' に保存しました。\")\n",
    "\n",
    "# --- 次のステップへの準備 ---\n",
    "print(f\"\\n=== 次のステップへの準備 ===\")\n",
    "consumption_columns = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in consumption_columns:\n",
    "    print(f\"  '{col}' の欠損値数: {all_data[col].isnull().sum()}\")\n",
    "\n",
    "print(\"\\n次は、これらの消費金額列の欠損値を回帰モデルで補完します。\")\n",
    "# 次のセル (セル 14) で進めていきましょう。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "034a44f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 消費金額列の欠損値補完の準備 ===\n",
      "--- 各列の現在の欠損値数 ---\n",
      "  'RoomService': 263\n",
      "  'FoodCourt': 289\n",
      "  'ShoppingMall': 306\n",
      "  'Spa': 284\n",
      "  'VRDeck': 268\n",
      "========== 'RoomService' の補完処理 ==========\n",
      "  RoomService が欠損しているデータ数: 263\n",
      "  補完に使用する特徴量: ['HomePlanet', 'CryoSleep', 'Destination', 'Deck', 'Side', 'Age', 'VIP', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
      "  RoomService が非欠損のデータ数: 12707\n",
      "  --- 特徴量の前処理 ---\n",
      "    VIP 列を int に変換しました。\n",
      "    特徴量前処理完了\n",
      "  --- モデルの定義 ---\n",
      "    LightGBM Regressor: CPU 使用設定\n",
      "    XGBoost Regressor: CPU 使用設定 (tree_method='hist')\n",
      "    CatBoost Regressor: CPU 使用設定\n",
      "    RandomForest Regressor: 設定\n",
      "  --- モデル評価 (交差検証) ---\n",
      "    Evaluating LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39046/4097588874.py:66: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_spending_processed['VIP'] = X_spending_processed['VIP'].fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LightGBM - CV RMSE: 521.64 (+/- 116.11), Time: 0.31s\n",
      "    Evaluating XGBoost...\n",
      "      XGBoost - CV RMSE: 535.20 (+/- 120.80), Time: 0.79s\n",
      "    Evaluating CatBoost...\n",
      "      CatBoost - CV RMSE: 535.73 (+/- 126.05), Time: 1.00s\n",
      "    Evaluating RandomForest...\n",
      "      RandomForest - CV RMSE: 552.66 (+/- 117.36), Time: 0.71s\n",
      "  --- モデル比較結果 (CV RMSE - 小さいほど良い) ---\n",
      "    LightGBM: RMSE=521.64 (Time: 0.31s)\n",
      "    XGBoost: RMSE=535.20 (Time: 0.79s)\n",
      "    CatBoost: RMSE=535.73 (Time: 1.00s)\n",
      "    RandomForest: RMSE=552.66 (Time: 0.71s)\n",
      "  --- 'RoomService' 補完に最も適したモデル: LightGBM (CV RMSE: 521.64) ---\n",
      "  --- 'RoomService' 欠損値補完の実行 ---\n",
      "    'RoomService' 補完モデル (LightGBM) の学習...\n",
      "    学習完了\n",
      "    'RoomService' 欠損値の予測...\n",
      "    予測された RoomService (最初の10件): [-2.99617074e+00  6.88484510e+02  4.32098386e+00  1.64968213e+03\n",
      "  5.67414724e+02  1.18491060e+02 -1.39686428e+00  4.01774352e+02\n",
      "  1.61098604e+02  9.54800323e+01]\n",
      "    予測結果のデータ型: float64\n",
      "    'RoomService' 補完結果の反映...\n",
      "    'RoomService' 列の欠損値が補完されました。\n",
      "========== 'FoodCourt' の補完処理 ==========\n",
      "  FoodCourt が欠損しているデータ数: 289\n",
      "  補完に使用する特徴量: ['HomePlanet', 'CryoSleep', 'Destination', 'Deck', 'Side', 'Age', 'VIP', 'RoomService', 'ShoppingMall', 'Spa', 'VRDeck']\n",
      "  FoodCourt が非欠損のデータ数: 12681\n",
      "  --- 特徴量の前処理 ---\n",
      "    VIP 列を int に変換しました。\n",
      "    特徴量前処理完了\n",
      "  --- モデルの定義 ---\n",
      "    LightGBM Regressor: CPU 使用設定\n",
      "    XGBoost Regressor: CPU 使用設定 (tree_method='hist')\n",
      "    CatBoost Regressor: CPU 使用設定\n",
      "    RandomForest Regressor: 設定\n",
      "  --- モデル評価 (交差検証) ---\n",
      "    Evaluating LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39046/4097588874.py:210: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  features_for_prediction_spending_df['VIP'] = features_for_prediction_spending_df['VIP'].fillna(False)\n",
      "/tmp/ipykernel_39046/4097588874.py:66: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_spending_processed['VIP'] = X_spending_processed['VIP'].fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LightGBM - CV RMSE: 1236.94 (+/- 268.08), Time: 0.27s\n",
      "    Evaluating XGBoost...\n",
      "      XGBoost - CV RMSE: 1235.03 (+/- 288.96), Time: 0.39s\n",
      "    Evaluating CatBoost...\n",
      "      CatBoost - CV RMSE: 1242.11 (+/- 291.63), Time: 1.01s\n",
      "    Evaluating RandomForest...\n",
      "      RandomForest - CV RMSE: 1248.36 (+/- 294.60), Time: 0.71s\n",
      "  --- モデル比較結果 (CV RMSE - 小さいほど良い) ---\n",
      "    XGBoost: RMSE=1235.03 (Time: 0.39s)\n",
      "    LightGBM: RMSE=1236.94 (Time: 0.27s)\n",
      "    CatBoost: RMSE=1242.11 (Time: 1.01s)\n",
      "    RandomForest: RMSE=1248.36 (Time: 0.71s)\n",
      "  --- 'FoodCourt' 補完に最も適したモデル: XGBoost (CV RMSE: 1235.03) ---\n",
      "  --- 'FoodCourt' 欠損値補完の実行 ---\n",
      "    'FoodCourt' 補完モデル (XGBoost) の学習...\n",
      "    学習完了\n",
      "    'FoodCourt' 欠損値の予測...\n",
      "    予測された FoodCourt (最初の10件): [579.28107   12.524335 409.04984  883.4723    29.73364  508.30164\n",
      " 131.06503   45.045822 153.13873   21.821037]\n",
      "    予測結果のデータ型: float32\n",
      "    'FoodCourt' 補完結果の反映...\n",
      "    'FoodCourt' 列の欠損値が補完されました。\n",
      "========== 'ShoppingMall' の補完処理 ==========\n",
      "  ShoppingMall が欠損しているデータ数: 306\n",
      "  補完に使用する特徴量: ['HomePlanet', 'CryoSleep', 'Destination', 'Deck', 'Side', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'Spa', 'VRDeck']\n",
      "  ShoppingMall が非欠損のデータ数: 12664\n",
      "  --- 特徴量の前処理 ---\n",
      "    VIP 列を int に変換しました。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39046/4097588874.py:210: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  features_for_prediction_spending_df['VIP'] = features_for_prediction_spending_df['VIP'].fillna(False)\n",
      "/tmp/ipykernel_39046/4097588874.py:66: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_spending_processed['VIP'] = X_spending_processed['VIP'].fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    特徴量前処理完了\n",
      "  --- モデルの定義 ---\n",
      "    LightGBM Regressor: CPU 使用設定\n",
      "    XGBoost Regressor: CPU 使用設定 (tree_method='hist')\n",
      "    CatBoost Regressor: CPU 使用設定\n",
      "    RandomForest Regressor: 設定\n",
      "  --- モデル評価 (交差検証) ---\n",
      "    Evaluating LightGBM...\n",
      "      LightGBM - CV RMSE: 502.43 (+/- 214.99), Time: 0.30s\n",
      "    Evaluating XGBoost...\n",
      "      XGBoost - CV RMSE: 511.06 (+/- 232.89), Time: 0.53s\n",
      "    Evaluating CatBoost...\n",
      "      CatBoost - CV RMSE: 517.04 (+/- 230.91), Time: 1.21s\n",
      "    Evaluating RandomForest...\n",
      "      RandomForest - CV RMSE: 532.41 (+/- 229.71), Time: 0.91s\n",
      "  --- モデル比較結果 (CV RMSE - 小さいほど良い) ---\n",
      "    LightGBM: RMSE=502.43 (Time: 0.30s)\n",
      "    XGBoost: RMSE=511.06 (Time: 0.53s)\n",
      "    CatBoost: RMSE=517.04 (Time: 1.21s)\n",
      "    RandomForest: RMSE=532.41 (Time: 0.91s)\n",
      "  --- 'ShoppingMall' 補完に最も適したモデル: LightGBM (CV RMSE: 502.43) ---\n",
      "  --- 'ShoppingMall' 欠損値補完の実行 ---\n",
      "    'ShoppingMall' 補完モデル (LightGBM) の学習...\n",
      "    学習完了\n",
      "    'ShoppingMall' 欠損値の予測...\n",
      "    予測された ShoppingMall (最初の10件): [4.53222808e+00 5.34364634e+02 5.61178333e+00 5.67366345e+00\n",
      " 4.58874666e+00 6.06536584e+00 5.27709940e-02 2.62339477e+00\n",
      " 2.03784077e+02 6.84476773e+00]\n",
      "    予測結果のデータ型: float64\n",
      "    'ShoppingMall' 補完結果の反映...\n",
      "    'ShoppingMall' 列の欠損値が補完されました。\n",
      "========== 'Spa' の補完処理 ==========\n",
      "  Spa が欠損しているデータ数: 284\n",
      "  補完に使用する特徴量: ['HomePlanet', 'CryoSleep', 'Destination', 'Deck', 'Side', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'VRDeck']\n",
      "  Spa が非欠損のデータ数: 12686\n",
      "  --- 特徴量の前処理 ---\n",
      "    VIP 列を int に変換しました。\n",
      "    特徴量前処理完了\n",
      "  --- モデルの定義 ---\n",
      "    LightGBM Regressor: CPU 使用設定\n",
      "    XGBoost Regressor: CPU 使用設定 (tree_method='hist')\n",
      "    CatBoost Regressor: CPU 使用設定\n",
      "    RandomForest Regressor: 設定\n",
      "  --- モデル評価 (交差検証) ---\n",
      "    Evaluating LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39046/4097588874.py:210: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  features_for_prediction_spending_df['VIP'] = features_for_prediction_spending_df['VIP'].fillna(False)\n",
      "/tmp/ipykernel_39046/4097588874.py:66: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_spending_processed['VIP'] = X_spending_processed['VIP'].fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LightGBM - CV RMSE: 972.18 (+/- 227.20), Time: 0.33s\n",
      "    Evaluating XGBoost...\n",
      "      XGBoost - CV RMSE: 988.75 (+/- 169.82), Time: 1.05s\n",
      "    Evaluating CatBoost...\n",
      "      CatBoost - CV RMSE: 969.86 (+/- 206.94), Time: 1.55s\n",
      "    Evaluating RandomForest...\n",
      "      RandomForest - CV RMSE: 982.73 (+/- 219.13), Time: 0.91s\n",
      "  --- モデル比較結果 (CV RMSE - 小さいほど良い) ---\n",
      "    CatBoost: RMSE=969.86 (Time: 1.55s)\n",
      "    LightGBM: RMSE=972.18 (Time: 0.33s)\n",
      "    RandomForest: RMSE=982.73 (Time: 0.91s)\n",
      "    XGBoost: RMSE=988.75 (Time: 1.05s)\n",
      "  --- 'Spa' 補完に最も適したモデル: CatBoost (CV RMSE: 969.86) ---\n",
      "  --- 'Spa' 欠損値補完の実行 ---\n",
      "    'Spa' 補完モデル (CatBoost) の学習...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39046/4097588874.py:210: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  features_for_prediction_spending_df['VIP'] = features_for_prediction_spending_df['VIP'].fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    学習完了\n",
      "    'Spa' 欠損値の予測...\n",
      "    予測された Spa (最初の10件): [ 179.92707484  160.08196376    4.30645167  -14.00330495  354.41593176\n",
      "  171.33938345   43.01522534 1477.65345541 1247.28524127  368.36854434]\n",
      "    予測結果のデータ型: float64\n",
      "    'Spa' 補完結果の反映...\n",
      "    'Spa' 列の欠損値が補完されました。\n",
      "========== 'VRDeck' の補完処理 ==========\n",
      "  VRDeck が欠損しているデータ数: 268\n",
      "  補完に使用する特徴量: ['HomePlanet', 'CryoSleep', 'Destination', 'Deck', 'Side', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa']\n",
      "  VRDeck が非欠損のデータ数: 12702\n",
      "  --- 特徴量の前処理 ---\n",
      "    VIP 列を int に変換しました。\n",
      "    特徴量前処理完了\n",
      "  --- モデルの定義 ---\n",
      "    LightGBM Regressor: CPU 使用設定\n",
      "    XGBoost Regressor: CPU 使用設定 (tree_method='hist')\n",
      "    CatBoost Regressor: CPU 使用設定\n",
      "    RandomForest Regressor: 設定\n",
      "  --- モデル評価 (交差検証) ---\n",
      "    Evaluating LightGBM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39046/4097588874.py:66: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_spending_processed['VIP'] = X_spending_processed['VIP'].fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LightGBM - CV RMSE: 1006.49 (+/- 219.69), Time: 0.33s\n",
      "    Evaluating XGBoost...\n",
      "      XGBoost - CV RMSE: 1016.76 (+/- 240.52), Time: 0.77s\n",
      "    Evaluating CatBoost...\n",
      "      CatBoost - CV RMSE: 1008.24 (+/- 233.78), Time: 1.60s\n",
      "    Evaluating RandomForest...\n",
      "      RandomForest - CV RMSE: 1004.53 (+/- 253.40), Time: 0.82s\n",
      "  --- モデル比較結果 (CV RMSE - 小さいほど良い) ---\n",
      "    RandomForest: RMSE=1004.53 (Time: 0.82s)\n",
      "    LightGBM: RMSE=1006.49 (Time: 0.33s)\n",
      "    CatBoost: RMSE=1008.24 (Time: 1.60s)\n",
      "    XGBoost: RMSE=1016.76 (Time: 0.77s)\n",
      "  --- 'VRDeck' 補完に最も適したモデル: RandomForest (CV RMSE: 1004.53) ---\n",
      "  --- 'VRDeck' 欠損値補完の実行 ---\n",
      "    'VRDeck' 補完モデル (RandomForest) の学習...\n",
      "    学習完了\n",
      "    'VRDeck' 欠損値の予測...\n",
      "    予測された VRDeck (最初の10件): [  0.           0.           0.         159.1646326    0.\n",
      " 458.81649047   0.         343.73536756 382.38412486   0.        ]\n",
      "    予測結果のデータ型: float64\n",
      "    'VRDeck' 補完結果の反映...\n",
      "    'VRDeck' 列の欠損値が補完されました。\n",
      "==================== すべての消費金額列の補完完了 ====================\n",
      "--- 補完後の各列の欠損値数 ---\n",
      "  'RoomService': 0\n",
      "  'FoodCourt': 0\n",
      "  'ShoppingMall': 0\n",
      "  'Spa': 0\n",
      "  'VRDeck': 0\n",
      "--- 新しいCSVファイルへの保存 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39046/4097588874.py:210: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  features_for_prediction_spending_df['VIP'] = features_for_prediction_spending_df['VIP'].fillna(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  補完後の全データを '../data/all_data_imputed_step7_Spending.csv' に保存しました。\n",
      "=== 最終ステップへの準備 ===\n",
      "--- その他の欠損値状況 ---\n",
      "Name            294\n",
      "Transported    4277\n",
      "dtype: int64\n",
      "データの前処理と欠損値補完が完了しました!\n",
      "これで、モデル学習用のデータセットが完成しました。\n"
     ]
    }
   ],
   "source": [
    "# セル 14: 消費金額列 (RoomService, FoodCourt, ...) の欠損値補完\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "# --- 前提条件 ---\n",
    "# all_data は Cabin まで補完された状態 (../data/all_data_imputed_step6_Cabin.csv から読み込み済み or メモリ上)\n",
    "# ここでは all_data が既に更新されている前提\n",
    "\n",
    "# 消費金額列のリスト\n",
    "consumption_columns = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "print(\"=== 消費金額列の欠損値補完の準備 ===\")\n",
    "print(\"--- 各列の現在の欠損値数 ---\")\n",
    "for col in consumption_columns:\n",
    "    print(f\"  '{col}': {all_data[col].isnull().sum()}\")\n",
    "\n",
    "# --- 共通の特徴量選定 ---\n",
    "# 消費金額の予測に使えそうな特徴量\n",
    "# これまで補完したカテゴリ変数 (HomePlanet, CryoSleep, Destination, Deck, Side) と Age, VIP を使用\n",
    "# 他の消費金額も特徴量に含める (相互に関連があるため)\n",
    "common_features_for_spending = [\n",
    "    'HomePlanet', 'CryoSleep', 'Destination', 'Deck', 'Side', 'Age', 'VIP',\n",
    "    # 他の消費金額列は後で追加します\n",
    "]\n",
    "\n",
    "# --- 各消費金額列の補完処理 ---\n",
    "for target_col in consumption_columns:\n",
    "    print(f\"{'='*10} '{target_col}' の補完処理 {'='*10}\")\n",
    "    \n",
    "    # --- 1. 補完対象データの特定 ---\n",
    "    missing_mask = all_data[target_col].isnull()\n",
    "    missing_indices = all_data[missing_mask].index\n",
    "    print(f\"  {target_col} が欠損しているデータ数: {len(missing_indices)}\")\n",
    "\n",
    "    # --- 2. 特徴量の選定 (他の消費金額列を含める) ---\n",
    "    # ターゲット列以外の消費金額を特徴量に追加\n",
    "    features_for_this_target = common_features_for_spending + [col for col in consumption_columns if col != target_col]\n",
    "    print(f\"  補完に使用する特徴量: {features_for_this_target}\")\n",
    "\n",
    "    # --- 3. モデル学習用データの準備 (ターゲット列が非欠損のデータ) ---\n",
    "    non_null_target_df = all_data[all_data[target_col].notnull()].copy()\n",
    "    print(f\"  {target_col} が非欠損のデータ数: {len(non_null_target_df)}\")\n",
    "\n",
    "    # 特徴量と目的変数の分離\n",
    "    X_spending = non_null_target_df[features_for_this_target].copy()\n",
    "    y_spending = non_null_target_df[target_col].copy() # float64 型 (数値)\n",
    "\n",
    "    # --- 4. 特徴量の前処理 ---\n",
    "    print(f\"  --- 特徴量の前処理 ---\")\n",
    "    # - カテゴリ変数の処理 (HomePlanet, CryoSleep, Destination, Deck, Side)\n",
    "    #   One-Hot Encoding を使用します。\n",
    "    #   dummy_na=True で欠損もカテゴリ化します。\n",
    "    X_spending_processed = pd.get_dummies(X_spending, columns=['HomePlanet', 'CryoSleep', 'Destination', 'Deck', 'Side'], dummy_na=True)\n",
    "    \n",
    "    # - バイナリ変数の処理 (VIP)\n",
    "    #   欠損値は False として扱います。\n",
    "    X_spending_processed['VIP'] = X_spending_processed['VIP'].fillna(False)\n",
    "    # object 型 (True/False or 'True'/'False') -> bool -> int\n",
    "    X_spending_processed['VIP'] = X_spending_processed['VIP'].map({'True': True, 'False': False, True: True, False: False})\n",
    "    X_spending_processed['VIP'] = X_spending_processed['VIP'].astype(int)\n",
    "    print(\"    VIP 列を int に変換しました。\")\n",
    "\n",
    "    # - 数値変数 (他の消費金額列) の欠損値処理\n",
    "    #   学習データの平均値で補完します。\n",
    "    other_spending_cols = [col for col in consumption_columns if col != target_col]\n",
    "    numeric_cols_for_spending = other_spending_cols + ['Age']\n",
    "    for col in numeric_cols_for_spending:\n",
    "        if col in X_spending_processed.columns: # 存在する場合のみ処理\n",
    "            X_spending_processed[col] = X_spending_processed[col].fillna(X_spending_processed[col].mean())\n",
    "    \n",
    "    print(\"    特徴量前処理完了\")\n",
    "\n",
    "    # --- 5. モデルの定義 (CPU モード) ---\n",
    "    print(f\"  --- モデルの定義 ---\")\n",
    "    models_spending = {}\n",
    "    \n",
    "    # LightGBM Regressor (CPU)\n",
    "    lgb_params_spending = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'n_estimators': 100,\n",
    "        'verbose': -1,\n",
    "        'random_state': 42,\n",
    "        'device': 'cpu'\n",
    "    }\n",
    "    print(\"    LightGBM Regressor: CPU 使用設定\")\n",
    "    models_spending['LightGBM'] = lgb.LGBMRegressor(**lgb_params_spending)\n",
    "\n",
    "    # XGBoost Regressor (CPU)\n",
    "    xgb_params_spending = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'booster': 'gbtree',\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.05,\n",
    "        'n_estimators': 100,\n",
    "        'random_state': 42,\n",
    "        'tree_method': 'hist'\n",
    "    }\n",
    "    print(\"    XGBoost Regressor: CPU 使用設定 (tree_method='hist')\")\n",
    "    models_spending['XGBoost'] = xgb.XGBRegressor(**xgb_params_spending, enable_categorical=False) # OneHot済みなのでFalse\n",
    "\n",
    "    # CatBoost Regressor (CPU)\n",
    "    cb_params_spending = {\n",
    "        'loss_function': 'RMSE',\n",
    "        'eval_metric': 'RMSE',\n",
    "        'iterations': 100,\n",
    "        'depth': 6,\n",
    "        'learning_rate': 0.05,\n",
    "        'random_seed': 42,\n",
    "        'verbose': False,\n",
    "        'task_type': 'CPU'\n",
    "    }\n",
    "    print(\"    CatBoost Regressor: CPU 使用設定\")\n",
    "    models_spending['CatBoost'] = cb.CatBoostRegressor(**cb_params_spending)\n",
    "\n",
    "    # RandomForest Regressor\n",
    "    rf_params_spending = {\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 6,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    print(\"    RandomForest Regressor: 設定\")\n",
    "    models_spending['RandomForest'] = RandomForestRegressor(**rf_params_spending)\n",
    "\n",
    "    # --- 6. モデル評価 (交差検証) ---\n",
    "    print(f\"  --- モデル評価 (交差検証) ---\")\n",
    "    # 交差検証の設定 (回帰用)\n",
    "    cv_folds = 5\n",
    "    kf_spending = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    # 回帰の評価指標: RMSE (Root Mean Squared Error) の符号を反転させたもの (neg_mean_squared_error)\n",
    "    scoring_metric_spending = 'neg_mean_squared_error'\n",
    "    model_scores_spending = {}\n",
    "    model_times_spending = {}\n",
    "\n",
    "    for name, model in models_spending.items():\n",
    "        print(f\"    Evaluating {name}...\")\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            # n_jobs=1 にして、並列処理によるトラブルを避ける\n",
    "            scores = cross_val_score(model, X_spending_processed, y_spending, cv=kf_spending, scoring=scoring_metric_spending, n_jobs=1)\n",
    "            # scores は負のMSE。RMSEにするには sqrt(-score) が必要。\n",
    "            rmse_scores = np.sqrt(-scores)\n",
    "        except Exception as e:\n",
    "            print(f\"      Error during CV for {name}: {e}\")\n",
    "            model_scores_spending[name] = np.nan\n",
    "            model_times_spending[name] = time.time() - start_time\n",
    "            continue\n",
    "        end_time = time.time()\n",
    "        mean_rmse = rmse_scores.mean()\n",
    "        std_rmse = rmse_scores.std()\n",
    "        elapsed_time = end_time - start_time\n",
    "        model_scores_spending[name] = mean_rmse # RMSEの平均を格納\n",
    "        model_times_spending[name] = elapsed_time\n",
    "        print(f\"      {name} - CV RMSE: {mean_rmse:.2f} (+/- {std_rmse * 2:.2f}), Time: {elapsed_time:.2f}s\")\n",
    "\n",
    "    # --- 7. 結果出力と最良モデルの選択 ---\n",
    "    print(f\"  --- モデル比較結果 (CV RMSE - 小さいほど良い) ---\")\n",
    "    # NaN を除外してソート (RMSEが小さい方が良いので reverse=False)\n",
    "    sorted_models_spending = sorted(\n",
    "        [(name, score) for name, score in model_scores_spending.items() if not np.isnan(score)],\n",
    "        key=lambda item: item[1], reverse=False\n",
    "    )\n",
    "    for name, score in sorted_models_spending:\n",
    "        print(f\"    {name}: RMSE={score:.2f} (Time: {model_times_spending[name]:.2f}s)\")\n",
    "\n",
    "    if not sorted_models_spending:\n",
    "        print(f\"  --- '{target_col}' のモデル評価結果がありません ---\")\n",
    "        continue # 次の列へ\n",
    "\n",
    "    best_model_name_spending, best_model_score_spending = sorted_models_spending[0]\n",
    "    print(f\"  --- '{target_col}' 補完に最も適したモデル: {best_model_name_spending} (CV RMSE: {best_model_score_spending:.2f}) ---\")\n",
    "\n",
    "    # --- 8. 最良モデルで欠損値補完の実行 ---\n",
    "    print(f\"  --- '{target_col}' 欠損値補完の実行 ---\")\n",
    "    \n",
    "    # a. 補完に使用する特徴量の準備 (欠損行のみ)\n",
    "    features_for_prediction_spending_df = all_data.loc[missing_mask, features_for_this_target].copy()\n",
    "    \n",
    "    # b. 特徴量の前処理 (学習時と同様)\n",
    "    #    - カテゴリ変数の処理 (HomePlanet, CryoSleep, Destination, Deck, Side)\n",
    "    features_for_prediction_spending_df = pd.get_dummies(features_for_prediction_spending_df, columns=['HomePlanet', 'CryoSleep', 'Destination', 'Deck', 'Side'], dummy_na=True)\n",
    "    \n",
    "    #    - 学習データの One-Hot 後のカラムに合わせる\n",
    "    #      `X_spending_processed` のカラムが基準\n",
    "    for col in X_spending_processed.columns: # 学習時のカラム\n",
    "        if col not in features_for_prediction_spending_df.columns:\n",
    "            features_for_prediction_spending_df[col] = 0 # 学習時にあったが予測時にない列は0で追加\n",
    "    for col in features_for_prediction_spending_df.columns:\n",
    "        if col not in X_spending_processed.columns:\n",
    "            features_for_prediction_spending_df.drop(columns=[col], inplace=True) # 予測時にあったが学習時にない列は削除\n",
    "    \n",
    "    #    - カラムの並び順を学習時と一致させる\n",
    "    features_for_prediction_spending_df = features_for_prediction_spending_df[X_spending_processed.columns]\n",
    "    \n",
    "    #    - バイナリ変数の処理 (VIP)\n",
    "    features_for_prediction_spending_df['VIP'] = features_for_prediction_spending_df['VIP'].fillna(False)\n",
    "    features_for_prediction_spending_df['VIP'] = features_for_prediction_spending_df['VIP'].map({'True': True, 'False': False, True: True, False: False})\n",
    "    features_for_prediction_spending_df['VIP'] = features_for_prediction_spending_df['VIP'].astype(int)\n",
    "    \n",
    "    #    - 数値変数 (他の消費金額列, Age) の欠損値処理 (学習データの平均値で補完 - モデル入力用)\n",
    "    #      重要: 学習データ X_spending_processed の平均値を使う！\n",
    "    for col in numeric_cols_for_spending:\n",
    "        if col in features_for_prediction_spending_df.columns:\n",
    "            # 学習データの平均値を取得\n",
    "            train_mean = X_spending_processed[col].mean()\n",
    "            features_for_prediction_spending_df[col] = features_for_prediction_spending_df[col].fillna(train_mean)\n",
    "\n",
    "    # c. モデルの学習\n",
    "    print(f\"    '{target_col}' 補完モデル ({best_model_name_spending}) の学習...\")\n",
    "    final_imputer_model_spending = models_spending[best_model_name_spending]\n",
    "    try:\n",
    "        final_imputer_model_spending.fit(X_spending_processed, y_spending)\n",
    "        print(\"    学習完了\")\n",
    "    except Exception as e:\n",
    "        print(f\"    '{target_col}' モデルの学習中にエラーが発生しました: {e}\")\n",
    "        continue # 次の列へ\n",
    "\n",
    "    # d. 欠損値の予測\n",
    "    print(f\"    '{target_col}' 欠損値の予測...\")\n",
    "    try:\n",
    "        predicted_values = final_imputer_model_spending.predict(features_for_prediction_spending_df)\n",
    "        # 予測結果は数値 (float) の配列であることを確認\n",
    "        print(f\"    予測された {target_col} (最初の10件): {predicted_values[:10]}\")\n",
    "        print(f\"    予測結果のデータ型: {predicted_values.dtype}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    '{target_col}' モデルの予測中にエラーが発生しました: {e}\")\n",
    "        continue # 次の列へ\n",
    "\n",
    "    # e. 元のデータフレームに補完結果を反映\n",
    "    print(f\"    '{target_col}' 補完結果の反映...\")\n",
    "    # 予測結果 (数値配列) を直接代入\n",
    "    all_data.loc[missing_indices, target_col] = predicted_values\n",
    "    print(f\"    '{target_col}' 列の欠損値が補完されました。\")\n",
    "\n",
    "# --- すべての列の補完が完了 ---\n",
    "print(f\"{'='*20} すべての消費金額列の補完完了 {'='*20}\")\n",
    "print(\"--- 補完後の各列の欠損値数 ---\")\n",
    "for col in consumption_columns:\n",
    "    print(f\"  '{col}': {all_data[col].isnull().sum()}\")\n",
    "\n",
    "# --- 新しいCSVファイルへの保存 ---\n",
    "print(f\"--- 新しいCSVファイルへの保存 ---\")\n",
    "data_dir = \"../data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    print(f\"  ディレクトリ '{data_dir}' を作成しました。\")\n",
    "\n",
    "output_file_path_final = os.path.join(data_dir, 'all_data_imputed_step7_Spending.csv')\n",
    "all_data.to_csv(output_file_path_final, index=False)\n",
    "print(f\"  補完後の全データを '{output_file_path_final}' に保存しました。\")\n",
    "\n",
    "# --- 最終ステップへの準備 ---\n",
    "print(f\"=== 最終ステップへの準備 ===\")\n",
    "# 残る欠損値の確認 (Name など)\n",
    "print(\"--- その他の欠損値状況 ---\")\n",
    "print(all_data.isnull().sum()[all_data.isnull().sum() > 0])\n",
    "\n",
    "print(\"データの前処理と欠損値補完が完了しました!\")\n",
    "print(\"これで、モデル学習用のデータセットが完成しました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50baa5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 最終補完データの欠損値状況 ===\n",
      "欠損値がある列:\n",
      "Name            294\n",
      "Transported    4277\n",
      "dtype: int64\n",
      "--- 確認完了 ---\n"
     ]
    }
   ],
   "source": [
    "# セル 15: 最終補完データの欠損値状況確認\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- 最終補完データの読み込み ---\n",
    "final_data_path = '../data/all_data_imputed_step7_Spending.csv'\n",
    "\n",
    "if not os.path.exists(final_data_path):\n",
    "    raise FileNotFoundError(f\"ファイル '{final_data_path}' が見つかりません。前のステップが正しく完了しているか確認してください。\")\n",
    "\n",
    "print(\"=== 最終補完データの欠損値状況 ===\")\n",
    "final_data = pd.read_csv(final_data_path)\n",
    "\n",
    "# 欠損値の集計\n",
    "null_counts = final_data.isnull().sum()\n",
    "\n",
    "# 欠損値がある列のみ表示\n",
    "missing_data = null_counts[null_counts > 0]\n",
    "\n",
    "if missing_data.empty:\n",
    "    print(\"すべての列に欠損値はありません。\")\n",
    "else:\n",
    "    print(\"欠損値がある列:\")\n",
    "    print(missing_data)\n",
    "\n",
    "print(f\"--- 確認完了 ---\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
